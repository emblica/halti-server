{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to Halti documentation\n\n\nHalti is container orchestration service built by simplicity and high availability in mind.\n\n\n\n\nBuild\n\n\n\ndocker build -t emblica/halti-server .\n\n\n\n\nUsage\n\n\nPORT=4040\nMONGO_URI=mongodb://192.168.99.100:32768/halti\nPRODUCTION=no\n\n\n\n\ndocker run -d -p 10.4.1.224:4040:4040 --name halti-server --restart=always -e PORT=4040 -e MONGO_URI=mongodb://172.17.0.1/halti -e PRODUCTION=yes emb/halti-server\n\n\n\n\nScheduler\n\n\nHalti scheduler is implemented in clojure and can be found from here https://github.com/emblica/halti-server/blob/master/src/clojure/halti_server/scheduler.clj\n\n\nScheduler tries to work with these limits and optimize the container configuration:\n\n\nImplemented:\n \n\n- Try to find best usage of resources\n- Keep same instances of service in different machines\n- If there is capability that is needed for service try to put it to machine that provides those capabilities\n\n\nMissing features\n\n\n\n\nSecurity and authentication with all connections between cluster\n\n\n\n\nBugs\n\n\nnot known bugs currently only missing features\n\n\nLicense\n\n\nSee LICENCE\n\nCopyright \u00a9 2016 Emblica",
            "title": "Home"
        },
        {
            "location": "/#welcome-to-halti-documentation",
            "text": "Halti is container orchestration service built by simplicity and high availability in mind.",
            "title": "Welcome to Halti documentation"
        },
        {
            "location": "/#build",
            "text": "docker build -t emblica/halti-server .",
            "title": "Build"
        },
        {
            "location": "/#usage",
            "text": "PORT=4040\nMONGO_URI=mongodb://192.168.99.100:32768/halti\nPRODUCTION=no  docker run -d -p 10.4.1.224:4040:4040 --name halti-server --restart=always -e PORT=4040 -e MONGO_URI=mongodb://172.17.0.1/halti -e PRODUCTION=yes emb/halti-server",
            "title": "Usage"
        },
        {
            "location": "/#scheduler",
            "text": "Halti scheduler is implemented in clojure and can be found from here https://github.com/emblica/halti-server/blob/master/src/clojure/halti_server/scheduler.clj  Scheduler tries to work with these limits and optimize the container configuration:  Implemented:   \n- Try to find best usage of resources\n- Keep same instances of service in different machines\n- If there is capability that is needed for service try to put it to machine that provides those capabilities",
            "title": "Scheduler"
        },
        {
            "location": "/#missing-features",
            "text": "Security and authentication with all connections between cluster",
            "title": "Missing features"
        },
        {
            "location": "/#bugs",
            "text": "not known bugs currently only missing features",
            "title": "Bugs"
        },
        {
            "location": "/#license",
            "text": "See LICENCE \nCopyright \u00a9 2016 Emblica",
            "title": "License"
        },
        {
            "location": "/administration_and_usage/",
            "text": "Creating and managing services\n\n\nCreating services is explained briefly in \nGetting started\n but it works\nby issuing requests to service API endpoints.\n\n\nAPI documentation can be found from \nAPI/services\n\n\nStructure of service description\n\n\n{\n    \"name\": \"hello-world-service\",\n    \"cpu\": 0.1,\n    \"enabled\": true,\n    \"memory\": 128,\n    \"instances\": 1,\n    \"requirements\": [],\n    \"version\": \"v1\",\n    \"image\": \"busybox\",\n    \"command\": \"httpd -f -vv -p 8080\",\n    \"ports\": [\n        8080\n    ],\n    \"environment\": []\n}\n\n\n\n\n\n\nname\n is just arbitrary user recognizable name, it's recommended that it doesn't contain whitespaces though   \n\n\ncpu\n 1 CPU core of the host machine is same as 1 CPU core of halti. This is hard limit for scheduling but in reality the service isn't limited by this factor.\n\n\nmemory\n as MB of ram of the host machine. Also hard limit for scheduling but doesn't limit the actual container at runtime.\n\n\ninstances\n replica count of this service. Same instance is never running two replicas of the same instance in same time.\n\n\nrequirements\n list of strings to describe the requirements for this service such as \nssd\n or \nintranet\n or \ngpu\n. Service is never scheduled on that kind of instances where some of the requirements are missing.\n\n\nversion\n version of the service. Changing this also forces docker image fetch. Useful when upgrading service.\n\n\nimage\n registry name/path to the used docker image\n\n\ncommand\n (optional) field to use as command to run the image\n\n\nports\n published ports declaration, this is the port service inside container runs for, can also be UDP-port\n\n\nenvironment\n environment variables as key-value objects\n\n\n\n\nUpdating service\n\n\nNon-HA update\n\n\nSteps:\n1. Build docker image and push it to repository\n2. Issue \nPUT\n request to the service description and update at least new \nversion\n (different between previous, it can be a date for example) and also \nimage\n path if you must.\n3. Wait for new version of the container to deploy. In the time between pulling the new image and running that there will be small downtime.\n\n\nHA update\n\n\nSo called Green-Blue deployment is actually quite easy to handle\n\n\nSteps:\n1. Build docker image and push it to repository using new tag ie. \nmywebserver:v1\n -> \nmywebserver:v2\n\n2. Create new service (blue) and refer to that image. Have same port configuration as the \ngreen\n service.\n3. Wait for the new \ngreen\n service to deploy and maybe check it is working correctly by configuring some development loadbalancer to point to it. ie. \ngreen.service.example.com\n and \nblue.service.example.com\n and the production traffic will go to \nproduction.service.example.com\n\n4. After you're happy, issue \nPUT\n into the production LB and change it to point to the new \ngreen\n service instead of the \nblue\n.\n5. If you want to rollback just issue another \nPUT\n into the production LB and change it point back to \nblue\n service.\n\n\nCreating and managing loadbalancers\n\n\nSee section from API docs.\n\n\nAdding new instances to cluster\n\n\nNew instaces can be added to cluster by just configuring the \nhalti-agent\n to run on that instance properly.\nIt will \ncall home\n to the pointed \nmaster\n and register itself to accept workload.\n\n\nIt's important to take care of \ncapabilities\n of new instances.\n\n\nRemoving instances from cluster\n\n\nAfter instance is missing from the cluster it will reschedule all it's containers to other instances if possible. (following the limits and requirements). Just taking node offline or even shutting down the \nhalit-agent\n will do that.\n\n\nProblem solving and common problems\n\n\nService doesn't run on any instance\n\n\nUsually the problem is in set of these:\n- Instance limits reached (scheduling error)\n- Docker image isn't pulled (registry or connection error)\n- Problem with image or command and it shuts down instantly (container error)\n\n\nIf you can't see your container to spin up make sure it's first scheduled by seeing if the service has instances listed under \nallocated_instances\n. (See asking the service state from the API)\n\n\nIf there is \nallocated_instances\n scheduler has already scheduled it to run in some node(s).\nSo then the problem is outside Halti master, somewhere else.\n\n\nTo investigate scheduling problems you should curl the following endpoint:\n\n\ncurl http://halti-master.example.com:4040/api/v1/state | jq .\n\n\n\n\n{\n  \"unscheduled\": [\n    {\n      \"problem\": {\n        \"host\": {\n          \"services\": [\n            \"1411c846-3353-45f0-a5d5-0fc35afa20bc\",\n            \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n            \"a60c6800-80f0-45e1-a985-5eaf7b83afcd\",\n            \"6eaad1ba-e14b-46cc-adfb-6d79cc786420\"\n          ],\n          \"containers\": [\n            \"6eaad1ba-e14b-46cc-adfb-6d79cc786420\",\n            \"a60c6800-80f0-45e1-a985-5eaf7b83afcd\",\n            \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n            \"1411c846-3353-45f0-a5d5-0fc35afa20bc\"\n          ],\n          \"capabilities\": [\n            \"public\"\n          ],\n          \"memory\": 402,\n          \"cpu\": 0.30000000000000004,\n          \"instance-id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\"\n        },\n        \"reason\": \"not-enough-memory\"\n      },\n      \"container-id\": 0,\n      \"requirements\": [],\n      \"cpu\": 0.1,\n      \"memory\": 1280,\n      \"service-id\": \"8744f08e-db63-40d3-b47d-87bbda8555a1\"\n    }\n  ]\n}\n\n\n\n\nAs you can see there is one service (\n8744f08e-db63-40d3-b47d-87bbda8555a1\n) unscheduled\nbecause it was otherwise suitable to run in instance \nc25269a3-7968-48e6-b5cf-b5ef68747675\n\nbut the intance didn't have any more memory available. To schedule that service you have to change memory requirements, vertically scale your nodes or add more nodes to your cluster.\n\n\nIn this situation there is only \n402MB\n free memory but the requirement is \n1280MB",
            "title": "Administration and usage"
        },
        {
            "location": "/administration_and_usage/#creating-and-managing-services",
            "text": "Creating services is explained briefly in  Getting started  but it works\nby issuing requests to service API endpoints.  API documentation can be found from  API/services",
            "title": "Creating and managing services"
        },
        {
            "location": "/administration_and_usage/#structure-of-service-description",
            "text": "{\n    \"name\": \"hello-world-service\",\n    \"cpu\": 0.1,\n    \"enabled\": true,\n    \"memory\": 128,\n    \"instances\": 1,\n    \"requirements\": [],\n    \"version\": \"v1\",\n    \"image\": \"busybox\",\n    \"command\": \"httpd -f -vv -p 8080\",\n    \"ports\": [\n        8080\n    ],\n    \"environment\": []\n}   name  is just arbitrary user recognizable name, it's recommended that it doesn't contain whitespaces though     cpu  1 CPU core of the host machine is same as 1 CPU core of halti. This is hard limit for scheduling but in reality the service isn't limited by this factor.  memory  as MB of ram of the host machine. Also hard limit for scheduling but doesn't limit the actual container at runtime.  instances  replica count of this service. Same instance is never running two replicas of the same instance in same time.  requirements  list of strings to describe the requirements for this service such as  ssd  or  intranet  or  gpu . Service is never scheduled on that kind of instances where some of the requirements are missing.  version  version of the service. Changing this also forces docker image fetch. Useful when upgrading service.  image  registry name/path to the used docker image  command  (optional) field to use as command to run the image  ports  published ports declaration, this is the port service inside container runs for, can also be UDP-port  environment  environment variables as key-value objects",
            "title": "Structure of service description"
        },
        {
            "location": "/administration_and_usage/#updating-service",
            "text": "",
            "title": "Updating service"
        },
        {
            "location": "/administration_and_usage/#non-ha-update",
            "text": "Steps:\n1. Build docker image and push it to repository\n2. Issue  PUT  request to the service description and update at least new  version  (different between previous, it can be a date for example) and also  image  path if you must.\n3. Wait for new version of the container to deploy. In the time between pulling the new image and running that there will be small downtime.",
            "title": "Non-HA update"
        },
        {
            "location": "/administration_and_usage/#ha-update",
            "text": "So called Green-Blue deployment is actually quite easy to handle  Steps:\n1. Build docker image and push it to repository using new tag ie.  mywebserver:v1  ->  mywebserver:v2 \n2. Create new service (blue) and refer to that image. Have same port configuration as the  green  service.\n3. Wait for the new  green  service to deploy and maybe check it is working correctly by configuring some development loadbalancer to point to it. ie.  green.service.example.com  and  blue.service.example.com  and the production traffic will go to  production.service.example.com \n4. After you're happy, issue  PUT  into the production LB and change it to point to the new  green  service instead of the  blue .\n5. If you want to rollback just issue another  PUT  into the production LB and change it point back to  blue  service.",
            "title": "HA update"
        },
        {
            "location": "/administration_and_usage/#creating-and-managing-loadbalancers",
            "text": "See section from API docs.",
            "title": "Creating and managing loadbalancers"
        },
        {
            "location": "/administration_and_usage/#adding-new-instances-to-cluster",
            "text": "New instaces can be added to cluster by just configuring the  halti-agent  to run on that instance properly.\nIt will  call home  to the pointed  master  and register itself to accept workload.  It's important to take care of  capabilities  of new instances.",
            "title": "Adding new instances to cluster"
        },
        {
            "location": "/administration_and_usage/#removing-instances-from-cluster",
            "text": "After instance is missing from the cluster it will reschedule all it's containers to other instances if possible. (following the limits and requirements). Just taking node offline or even shutting down the  halit-agent  will do that.",
            "title": "Removing instances from cluster"
        },
        {
            "location": "/administration_and_usage/#problem-solving-and-common-problems",
            "text": "",
            "title": "Problem solving and common problems"
        },
        {
            "location": "/administration_and_usage/#service-doesnt-run-on-any-instance",
            "text": "Usually the problem is in set of these:\n- Instance limits reached (scheduling error)\n- Docker image isn't pulled (registry or connection error)\n- Problem with image or command and it shuts down instantly (container error)  If you can't see your container to spin up make sure it's first scheduled by seeing if the service has instances listed under  allocated_instances . (See asking the service state from the API)  If there is  allocated_instances  scheduler has already scheduled it to run in some node(s).\nSo then the problem is outside Halti master, somewhere else.  To investigate scheduling problems you should curl the following endpoint:  curl http://halti-master.example.com:4040/api/v1/state | jq .  {\n  \"unscheduled\": [\n    {\n      \"problem\": {\n        \"host\": {\n          \"services\": [\n            \"1411c846-3353-45f0-a5d5-0fc35afa20bc\",\n            \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n            \"a60c6800-80f0-45e1-a985-5eaf7b83afcd\",\n            \"6eaad1ba-e14b-46cc-adfb-6d79cc786420\"\n          ],\n          \"containers\": [\n            \"6eaad1ba-e14b-46cc-adfb-6d79cc786420\",\n            \"a60c6800-80f0-45e1-a985-5eaf7b83afcd\",\n            \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n            \"1411c846-3353-45f0-a5d5-0fc35afa20bc\"\n          ],\n          \"capabilities\": [\n            \"public\"\n          ],\n          \"memory\": 402,\n          \"cpu\": 0.30000000000000004,\n          \"instance-id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\"\n        },\n        \"reason\": \"not-enough-memory\"\n      },\n      \"container-id\": 0,\n      \"requirements\": [],\n      \"cpu\": 0.1,\n      \"memory\": 1280,\n      \"service-id\": \"8744f08e-db63-40d3-b47d-87bbda8555a1\"\n    }\n  ]\n}  As you can see there is one service ( 8744f08e-db63-40d3-b47d-87bbda8555a1 ) unscheduled\nbecause it was otherwise suitable to run in instance  c25269a3-7968-48e6-b5cf-b5ef68747675 \nbut the intance didn't have any more memory available. To schedule that service you have to change memory requirements, vertically scale your nodes or add more nodes to your cluster.  In this situation there is only  402MB  free memory but the requirement is  1280MB",
            "title": "Service doesn't run on any instance"
        },
        {
            "location": "/architecture/",
            "text": "Architecture\n\n\nHalti has two essential components. Master-nodes and Worker-nodes.\n\n\nMasters\n\n\n\n\nRun Halti-server\n\n\nProvide API for the cluster\n\n\nSchedule and optimize services between healthy worker nodes\n\n\nKeep only one master scheduler as active in same time\n\n\n\n\nWorkers\n\n\n\n\nRun Halti agent\n\n\nSend heartbeat for master\n\n\nTry to maintain state that master hopes they have\n\n\n\n\nLoadbalancers\n\n\n\n\nRoutes TCP-traffic from outside to services\n\n\nTerminates SSL-connections",
            "title": "Architecture"
        },
        {
            "location": "/architecture/#architecture",
            "text": "Halti has two essential components. Master-nodes and Worker-nodes.",
            "title": "Architecture"
        },
        {
            "location": "/architecture/#masters",
            "text": "Run Halti-server  Provide API for the cluster  Schedule and optimize services between healthy worker nodes  Keep only one master scheduler as active in same time",
            "title": "Masters"
        },
        {
            "location": "/architecture/#workers",
            "text": "Run Halti agent  Send heartbeat for master  Try to maintain state that master hopes they have",
            "title": "Workers"
        },
        {
            "location": "/architecture/#loadbalancers",
            "text": "Routes TCP-traffic from outside to services  Terminates SSL-connections",
            "title": "Loadbalancers"
        },
        {
            "location": "/getting_started/",
            "text": "How to deploy Hello world?\n\n\nTo deploy Hello world we're expecting that you already have running Halti cluster with at least one master node and one worker node.\nThey may locate in single physical (or virtual) host but both systems have to be running.\n\n\nRequirements\n\n\n\n\nWorking Halti cluster running\n\n\ncurl\n\n\njq (for managing and formatting the output of curl)\n\n\n\n\nService\n\n\nFirst part is to create service - the running http process that can serve the Hello World-page.\n\n\nEasiest way is to use \nbusybox\n (https://hub.docker.com/_/busybox/) image.\nThe image is using port 8080 to run web server.\n\n\nFirst operation is to define the \nhello-world-service\n as JSON:\n\n\n{\n    \"name\": \"hello-world-service\",\n    \"cpu\": 0.1,\n    \"enabled\": true,\n    \"memory\": 128,\n    \"instances\": 1,\n    \"requirements\": [],\n    \"version\": \"v1\",\n    \"image\": \"busybox\",\n    \"command\": \"httpd -f -vv -p 8080\",\n    \"ports\": [\n        8080\n    ],\n    \"environment\": []\n}\n\n\n\n\nYou can find that service description from 'examples/' of the halti-server\nAfter that run following command from command line to create new service:\n\n\nHELLO_WORLD_SERVICE=$(curl -XPOST http://halti-master.example.com:4040/api/v1/services -d @examples/hello_world_service.json -H 'Content-Type: application/json' | jq -r .service.service_id)\n#% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n#                               Dload  Upload   Total   Spent    Left  Speed\n#100   507  100   268  100   239  21972  19594 --:--:-- --:--:-- --:--:-- 22333\necho $HELLO_WORLD_SERVICE\n# 4897c316-c7dd-4238-919f-cb8efce569ae\n\n\n\n\nCheck that your service is scheduled to run in some server:\n\n\ncurl \"http://halti-master.example.com:4040/api/v1/services/${HELLO_WORLD_SERVICE}\" | jq .\n\n\n\n\nPrints out:\n\n\n{\n  \"service\": {\n    \"requirements\": [],\n    \"name\": \"hello-world-service\",\n    \"allocated_instances\": [\n      \"c25269a3-7968-48e6-b5cf-b5ef68747675\"\n    ],\n    \"memory\": 128,\n    \"command\": \"httpd -f -vv -p 8080\",\n    \"running_on\": [],\n    \"ports\": [\n      {\n        \"protocol\": \"tcp\",\n        \"port\": 8080\n      }\n    ],\n    \"instances\": 1,\n    \"image\": \"busybox\",\n    \"environment\": [],\n    \"service_id\": \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n    \"version\": \"v1\",\n    \"enabled\": true,\n    \"cpu\": 0.1\n  }\n}\n\n\n\n\nThe \nallocated_instances\n shows all the instances the container is scheduled to run. It will take a little time to pull the image from repository.\n\n\nIf you are curious what is happening inside the instance you can do following:\n\n\n# Get latest 5 events from the allocated instance\ncurl \"http://halti-master.example.com:4040/api/v1/instances/c25269a3-7968-48e6-b5cf-b5ef68747675/events\" | jq '.events | .[-5:-1]'\n\n\n\n\nEvents look like this:\n\n\n[\n  {\n    \"meta\": \"busybox\",\n    \"event_type\": \"INFO\",\n    \"event\": \"PULL_START\",\n    \"instance_id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\",\n    \"timestamp\": \"2017-06-20T23:27:40.386Z\"\n  },\n  {\n    \"meta\": \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n    \"event_type\": \"INFO\",\n    \"event\": \"START_CONTAINER\",\n    \"instance_id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\",\n    \"timestamp\": \"2017-06-20T23:29:35.365Z\"\n  }\n]\n\n\n\n\nThere you can see that the instance started to pull the image and after that it started the container.\n\n\nIf you now issue the same command again than earlier you should see following output:\n\n\n{\n  \"service\": {\n    \"requirements\": [],\n    \"name\": \"hello-world-service\",\n    \"allocated_instances\": [\n      \"c25269a3-7968-48e6-b5cf-b5ef68747675\"\n    ],\n    \"memory\": 128,\n    \"command\": \"httpd -f -vv -p 8080\",\n    \"running_on\": [\n      {\n        \"instance_id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\",\n        \"address\": \"10.1.5.189\",\n        \"port\": 32768,\n        \"source\": 8080\n      }\n    ],\n    \"ports\": [\n      {\n        \"protocol\": \"tcp\",\n        \"port\": 8080\n      }\n    ],\n    \"instances\": 1,\n    \"image\": \"busybox\",\n    \"environment\": [],\n    \"service_id\": \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n    \"version\": \"v1\",\n    \"enabled\": true,\n    \"cpu\": 0.1\n  }\n}\n\n\n\n\nAs you can see now the service is running on instance \nc25269a3-7968-48e6-b5cf-b5ef68747675\n at port \n10.1.5.189:32768\n and it's accessible from internal network only.\n\n\nTo publish the service you must have \nloadbalancer\n\n\nLoadbalancer\n\n\nLoadbalancer is using \nLuotsi\n component to route HTTP traffic into services.\nIt works by reading the loadbalancer config endpoint and autoconfiguring \nHaproxy\n from that.\n\n\nTo get access to our just created \nhello-world-service\n we have to create loadbalancer for that.\n\n\n\n\nFirst edit your loadbalancer declaration at \nexamples/hello_world_loadbalancer.json\n and add service id of the \nhello-world-service\n into that.\n\n\n\n\n{\n    \"name\": \"hello-world-loadbalancer\",\n    \"enabled\": true,\n    \"hostname\": \"hello.example.com\",\n    \"service_id\": \"<hello-world-service-id>\",\n    \"source_port\": 8080,\n    \"force_https\": false,\n    \"ports\": {\"http\": true, \"https\": false}\n}\n\n\n\n\nThe source port (\nsource_port\n) is same as defined in service declaration (8080). We also disable HTTPS for this service because we're not using SSL-certificates in this getting started.\n\n\nforce_https\n is forcing HTTPS redirect in loadbalancer layer and it should be used in production.\n\n\nhostname\n is going to be matched into HTTPs \nHost\n-header and the routing is made based on that.\n\n\n\n\nAdd loadbalancer declaration to halti with curl\n\n\n\n\nHELLO_WORLD_LB=$(curl -XPOST http://halti-master.example.com:4040/api/v1/loadbalancers -d @examples/hello_world_loadbalancer.json -H 'Content-Type: application/json' | jq -r .loadbalancer.loadbalancer_id)\n\n\n\n\n\n\nAfter a few seconds the routing should be online and if you are pointing your dns into the edge nodes you should be able to access the \nhello-world-service\n by browsing \nhttp://hello.example.com\n\n\n\n\nTips\n\n\nIf you can't see your container to spin up make sure it's first scheduled by seeing if the service has instances listed under \nallocated_instances\n.\n\n\nIf there is \nallocated_instances\n scheduler has already scheduled it to run in some node(s).\nSo then the problem is outside Halti master, somewhere else.\n\n\nTo investigate scheduling problems you should curl the following endpoint:\n\n\ncurl http://halti-master.example.com:4040/api/v1/state | jq .\n\n\n\n\n{\n  \"unscheduled\": [\n    {\n      \"problem\": {\n        \"host\": {\n          \"services\": [\n            \"1411c846-3353-45f0-a5d5-0fc35afa20bc\",\n            \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n            \"a60c6800-80f0-45e1-a985-5eaf7b83afcd\",\n            \"6eaad1ba-e14b-46cc-adfb-6d79cc786420\"\n          ],\n          \"containers\": [\n            \"6eaad1ba-e14b-46cc-adfb-6d79cc786420\",\n            \"a60c6800-80f0-45e1-a985-5eaf7b83afcd\",\n            \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n            \"1411c846-3353-45f0-a5d5-0fc35afa20bc\"\n          ],\n          \"capabilities\": [\n            \"public\"\n          ],\n          \"memory\": 402,\n          \"cpu\": 0.30000000000000004,\n          \"instance-id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\"\n        },\n        \"reason\": \"not-enough-memory\"\n      },\n      \"container-id\": 0,\n      \"requirements\": [],\n      \"cpu\": 0.1,\n      \"memory\": 1280,\n      \"service-id\": \"8744f08e-db63-40d3-b47d-87bbda8555a1\"\n    }\n  ]\n}\n\n\n\n\nAs you can see there is one service (\n8744f08e-db63-40d3-b47d-87bbda8555a1\n) unscheduled\nbecause it was otherwise suitable to run in instance \nc25269a3-7968-48e6-b5cf-b5ef68747675\n\nbut the intance didn't have any more memory available. To schedule that service you have to change memory requirements, vertically scale your nodes or add more nodes to your cluster.\n\n\nIn this situation there is only \n402MB\n free memory but the requirement is \n1280MB\n\n\nList all of your services\n\n\ncurl http://halti-master.example.com:4040/api/v1/services | jq '.services | .[] | {name: .name, service: .service_id}'",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#how-to-deploy-hello-world",
            "text": "To deploy Hello world we're expecting that you already have running Halti cluster with at least one master node and one worker node.\nThey may locate in single physical (or virtual) host but both systems have to be running.",
            "title": "How to deploy Hello world?"
        },
        {
            "location": "/getting_started/#requirements",
            "text": "Working Halti cluster running  curl  jq (for managing and formatting the output of curl)",
            "title": "Requirements"
        },
        {
            "location": "/getting_started/#service",
            "text": "First part is to create service - the running http process that can serve the Hello World-page.  Easiest way is to use  busybox  (https://hub.docker.com/_/busybox/) image.\nThe image is using port 8080 to run web server.  First operation is to define the  hello-world-service  as JSON:  {\n    \"name\": \"hello-world-service\",\n    \"cpu\": 0.1,\n    \"enabled\": true,\n    \"memory\": 128,\n    \"instances\": 1,\n    \"requirements\": [],\n    \"version\": \"v1\",\n    \"image\": \"busybox\",\n    \"command\": \"httpd -f -vv -p 8080\",\n    \"ports\": [\n        8080\n    ],\n    \"environment\": []\n}  You can find that service description from 'examples/' of the halti-server\nAfter that run following command from command line to create new service:  HELLO_WORLD_SERVICE=$(curl -XPOST http://halti-master.example.com:4040/api/v1/services -d @examples/hello_world_service.json -H 'Content-Type: application/json' | jq -r .service.service_id)\n#% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n#                               Dload  Upload   Total   Spent    Left  Speed\n#100   507  100   268  100   239  21972  19594 --:--:-- --:--:-- --:--:-- 22333\necho $HELLO_WORLD_SERVICE\n# 4897c316-c7dd-4238-919f-cb8efce569ae  Check that your service is scheduled to run in some server:  curl \"http://halti-master.example.com:4040/api/v1/services/${HELLO_WORLD_SERVICE}\" | jq .  Prints out:  {\n  \"service\": {\n    \"requirements\": [],\n    \"name\": \"hello-world-service\",\n    \"allocated_instances\": [\n      \"c25269a3-7968-48e6-b5cf-b5ef68747675\"\n    ],\n    \"memory\": 128,\n    \"command\": \"httpd -f -vv -p 8080\",\n    \"running_on\": [],\n    \"ports\": [\n      {\n        \"protocol\": \"tcp\",\n        \"port\": 8080\n      }\n    ],\n    \"instances\": 1,\n    \"image\": \"busybox\",\n    \"environment\": [],\n    \"service_id\": \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n    \"version\": \"v1\",\n    \"enabled\": true,\n    \"cpu\": 0.1\n  }\n}  The  allocated_instances  shows all the instances the container is scheduled to run. It will take a little time to pull the image from repository.  If you are curious what is happening inside the instance you can do following:  # Get latest 5 events from the allocated instance\ncurl \"http://halti-master.example.com:4040/api/v1/instances/c25269a3-7968-48e6-b5cf-b5ef68747675/events\" | jq '.events | .[-5:-1]'  Events look like this:  [\n  {\n    \"meta\": \"busybox\",\n    \"event_type\": \"INFO\",\n    \"event\": \"PULL_START\",\n    \"instance_id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\",\n    \"timestamp\": \"2017-06-20T23:27:40.386Z\"\n  },\n  {\n    \"meta\": \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n    \"event_type\": \"INFO\",\n    \"event\": \"START_CONTAINER\",\n    \"instance_id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\",\n    \"timestamp\": \"2017-06-20T23:29:35.365Z\"\n  }\n]  There you can see that the instance started to pull the image and after that it started the container.  If you now issue the same command again than earlier you should see following output:  {\n  \"service\": {\n    \"requirements\": [],\n    \"name\": \"hello-world-service\",\n    \"allocated_instances\": [\n      \"c25269a3-7968-48e6-b5cf-b5ef68747675\"\n    ],\n    \"memory\": 128,\n    \"command\": \"httpd -f -vv -p 8080\",\n    \"running_on\": [\n      {\n        \"instance_id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\",\n        \"address\": \"10.1.5.189\",\n        \"port\": 32768,\n        \"source\": 8080\n      }\n    ],\n    \"ports\": [\n      {\n        \"protocol\": \"tcp\",\n        \"port\": 8080\n      }\n    ],\n    \"instances\": 1,\n    \"image\": \"busybox\",\n    \"environment\": [],\n    \"service_id\": \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n    \"version\": \"v1\",\n    \"enabled\": true,\n    \"cpu\": 0.1\n  }\n}  As you can see now the service is running on instance  c25269a3-7968-48e6-b5cf-b5ef68747675  at port  10.1.5.189:32768  and it's accessible from internal network only.  To publish the service you must have  loadbalancer",
            "title": "Service"
        },
        {
            "location": "/getting_started/#loadbalancer",
            "text": "Loadbalancer is using  Luotsi  component to route HTTP traffic into services.\nIt works by reading the loadbalancer config endpoint and autoconfiguring  Haproxy  from that.  To get access to our just created  hello-world-service  we have to create loadbalancer for that.   First edit your loadbalancer declaration at  examples/hello_world_loadbalancer.json  and add service id of the  hello-world-service  into that.   {\n    \"name\": \"hello-world-loadbalancer\",\n    \"enabled\": true,\n    \"hostname\": \"hello.example.com\",\n    \"service_id\": \"<hello-world-service-id>\",\n    \"source_port\": 8080,\n    \"force_https\": false,\n    \"ports\": {\"http\": true, \"https\": false}\n}  The source port ( source_port ) is same as defined in service declaration (8080). We also disable HTTPS for this service because we're not using SSL-certificates in this getting started.  force_https  is forcing HTTPS redirect in loadbalancer layer and it should be used in production.  hostname  is going to be matched into HTTPs  Host -header and the routing is made based on that.   Add loadbalancer declaration to halti with curl   HELLO_WORLD_LB=$(curl -XPOST http://halti-master.example.com:4040/api/v1/loadbalancers -d @examples/hello_world_loadbalancer.json -H 'Content-Type: application/json' | jq -r .loadbalancer.loadbalancer_id)   After a few seconds the routing should be online and if you are pointing your dns into the edge nodes you should be able to access the  hello-world-service  by browsing  http://hello.example.com",
            "title": "Loadbalancer"
        },
        {
            "location": "/getting_started/#tips",
            "text": "If you can't see your container to spin up make sure it's first scheduled by seeing if the service has instances listed under  allocated_instances .  If there is  allocated_instances  scheduler has already scheduled it to run in some node(s).\nSo then the problem is outside Halti master, somewhere else.  To investigate scheduling problems you should curl the following endpoint:  curl http://halti-master.example.com:4040/api/v1/state | jq .  {\n  \"unscheduled\": [\n    {\n      \"problem\": {\n        \"host\": {\n          \"services\": [\n            \"1411c846-3353-45f0-a5d5-0fc35afa20bc\",\n            \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n            \"a60c6800-80f0-45e1-a985-5eaf7b83afcd\",\n            \"6eaad1ba-e14b-46cc-adfb-6d79cc786420\"\n          ],\n          \"containers\": [\n            \"6eaad1ba-e14b-46cc-adfb-6d79cc786420\",\n            \"a60c6800-80f0-45e1-a985-5eaf7b83afcd\",\n            \"4897c316-c7dd-4238-919f-cb8efce569ae\",\n            \"1411c846-3353-45f0-a5d5-0fc35afa20bc\"\n          ],\n          \"capabilities\": [\n            \"public\"\n          ],\n          \"memory\": 402,\n          \"cpu\": 0.30000000000000004,\n          \"instance-id\": \"c25269a3-7968-48e6-b5cf-b5ef68747675\"\n        },\n        \"reason\": \"not-enough-memory\"\n      },\n      \"container-id\": 0,\n      \"requirements\": [],\n      \"cpu\": 0.1,\n      \"memory\": 1280,\n      \"service-id\": \"8744f08e-db63-40d3-b47d-87bbda8555a1\"\n    }\n  ]\n}  As you can see there is one service ( 8744f08e-db63-40d3-b47d-87bbda8555a1 ) unscheduled\nbecause it was otherwise suitable to run in instance  c25269a3-7968-48e6-b5cf-b5ef68747675 \nbut the intance didn't have any more memory available. To schedule that service you have to change memory requirements, vertically scale your nodes or add more nodes to your cluster.  In this situation there is only  402MB  free memory but the requirement is  1280MB",
            "title": "Tips"
        },
        {
            "location": "/getting_started/#list-all-of-your-services",
            "text": "curl http://halti-master.example.com:4040/api/v1/services | jq '.services | .[] | {name: .name, service: .service_id}'",
            "title": "List all of your services"
        },
        {
            "location": "/installation/",
            "text": "Using ansible for new cluster\n\n\nPlaybooks are here:\nhttps://github.com/emblica/halti-management-playbooks\n\n\nAnsible installs halti-cluster on predefined machines.\nIt also installs monitoring and metrics collection setup.\n\n\nAfter installation halti-master (and so the API) can be found at \n:4040\n\n\nThe Grafana by default is in \n:3000 and the InfluxDB \n:8083/8086\n\n\nDependencies\n\n\n\n\npython2 (because ansible)\n\n\ninstall dependencies\n\n\n\n\npip install ansible\n\n\n\n\nRunning\n\n\n\n\ninstall Halti against existing servers\n\n\n\n\nansible-playbook -i hosts site.yml --tags install\n\n\n\n\nSupport for capabilities\n\n\nYou can add halti supported capability-setting by defining \ncapabilities\n variable for each host.\n\n\nie. \ncapabilities=public,ssd\n\n\nNotes\n\n\n\n\nansible_eth1\n is assumed to be the private IP of the machine\n\n\nedit halti-nodes.yml if this is not the case\n\n\n\n\n\n\nHalti master will run at port 4040 by default\n\n\n\n\nOn Upcloud\n\n\nRunning whole playbook will provision and install a small Halti cluster on UpCloud.\n\n\nYou need to install additional dependencies if you want to provision the servers through UpClouds APIs\n\n\npip install upcloud_api\n\n\n\n\n\n\ncheck that \nupcloud-ansible\n submodule is loaded\n\n\n\n\nRunning\n\n\n\n\nprovision servers and install Halti cluster\n\n\n\n\nexport UPCLOUD_API_USER=user\nexport UPCLOUD_API_PASSWD=pass\nansible-playbook -i ./upcloud-ansible/inventory/upcloud.py -M ./upcloud-ansible/modules/ site.yml\n\n\n\n\nNotes\n\n\n\n\nansible_eth1\n is assumed to be the private IP of the machine\n\n\nedit halti-nodes.yml if this is not the case\n\n\n\n\n\n\nHalti master will run at port 4040 by default\n\n\nutils/test_tagging.py\n is used by \nhalti-servers\n to ensure the user has tagging permissions\n\n\nutils/destroy_cluster.py\n can be used to clean up (main usecase is integration testing)\n\n\n\n\nFrom command line\n\n\nMaster\n\n\nHalti-server is supposed to be run in at least one server.\n\n\nTo run the latest version of halti-server issue following commands:\n\n\n# Run mongodb\ndocker run --name mongodb -d mongo\n\n# Run Halti server (master)\ndocker run -d --restart=always --name=halti-master --env=\"PRODUCTION=yes\" --env=\"PORT=4040\" --env=\"MONGO_URI=mongodb://mongodb/halti\" -p <host-private-ip>:4040:4040/tcp --link mongodb emblica/halti-server\n\n\n\n\nWorker\n\n\nEach worker node must have halti-agent running on. Halti agent takes care of the container management.\n\n\nHalti-agent is stateless but it's recommended to mount volume for production usage so the state won't clutter with dead instances/hosts if container restarts by version upgrade or so.\n\n\nPORT_BIND_IP\n is special environment variable for the agent it will bind the services to.\n\n\nIt must be accessible from the loadbalancing edge nodes so it usually is the LAN-address of the halti worker machine.\n\n\ndocker run -d --restart=always --privileged -v /var/run/docker.sock:/var/run/docker.sock -e DOCKER_HOST=unix:///var/run/docker.sock -e HALTI_SERVER=https://halti-master-address:4040 -e PORT_BIND_IP=192.168.1.100 emblica/halti-agent\n\n\n\n\nLuotsi - loadbalancing\n\n\nUsually all halti worker nodes are also edge nodes but that is not a requirement.\n\n\nLuotsi has following dependencies:\n- latest stable Haproxy\n- latest stable Node.js\n\n\nInstalling luotsi\n\n\ngit clone https://github.com/emblica/luotsi.git\ncd luotsi\n# Install dependencies\nnpm install\n\n\n\n\nRunning luotsi\n\n\nBefore luotsi can be run you must first setup all the needed environment variables:\n\n\nSSL_ENABLED=true/false\nCERT_PATH=absolute path to certificate pem\nMAINTENANCE_PAGE=absolute path to haproxy compatible maintenance page\nSTATS_USER=username of haproxy status web gui\nSTATS_PASS=password of haproxy status web guy\nHALTI_URL=url of the halti master\n\n\n\n\nAfter environment variables are set just\n\n\nnode luotsi.js",
            "title": "Installation"
        },
        {
            "location": "/installation/#using-ansible-for-new-cluster",
            "text": "Playbooks are here:\nhttps://github.com/emblica/halti-management-playbooks  Ansible installs halti-cluster on predefined machines.\nIt also installs monitoring and metrics collection setup.  After installation halti-master (and so the API) can be found at  :4040  The Grafana by default is in  :3000 and the InfluxDB  :8083/8086",
            "title": "Using ansible for new cluster"
        },
        {
            "location": "/installation/#dependencies",
            "text": "python2 (because ansible)  install dependencies   pip install ansible",
            "title": "Dependencies"
        },
        {
            "location": "/installation/#running",
            "text": "install Halti against existing servers   ansible-playbook -i hosts site.yml --tags install",
            "title": "Running"
        },
        {
            "location": "/installation/#support-for-capabilities",
            "text": "You can add halti supported capability-setting by defining  capabilities  variable for each host.  ie.  capabilities=public,ssd",
            "title": "Support for capabilities"
        },
        {
            "location": "/installation/#notes",
            "text": "ansible_eth1  is assumed to be the private IP of the machine  edit halti-nodes.yml if this is not the case    Halti master will run at port 4040 by default",
            "title": "Notes"
        },
        {
            "location": "/installation/#on-upcloud",
            "text": "Running whole playbook will provision and install a small Halti cluster on UpCloud.  You need to install additional dependencies if you want to provision the servers through UpClouds APIs  pip install upcloud_api   check that  upcloud-ansible  submodule is loaded",
            "title": "On Upcloud"
        },
        {
            "location": "/installation/#running_1",
            "text": "provision servers and install Halti cluster   export UPCLOUD_API_USER=user\nexport UPCLOUD_API_PASSWD=pass\nansible-playbook -i ./upcloud-ansible/inventory/upcloud.py -M ./upcloud-ansible/modules/ site.yml",
            "title": "Running"
        },
        {
            "location": "/installation/#notes_1",
            "text": "ansible_eth1  is assumed to be the private IP of the machine  edit halti-nodes.yml if this is not the case    Halti master will run at port 4040 by default  utils/test_tagging.py  is used by  halti-servers  to ensure the user has tagging permissions  utils/destroy_cluster.py  can be used to clean up (main usecase is integration testing)",
            "title": "Notes"
        },
        {
            "location": "/installation/#from-command-line",
            "text": "",
            "title": "From command line"
        },
        {
            "location": "/installation/#master",
            "text": "Halti-server is supposed to be run in at least one server.  To run the latest version of halti-server issue following commands:  # Run mongodb\ndocker run --name mongodb -d mongo\n\n# Run Halti server (master)\ndocker run -d --restart=always --name=halti-master --env=\"PRODUCTION=yes\" --env=\"PORT=4040\" --env=\"MONGO_URI=mongodb://mongodb/halti\" -p <host-private-ip>:4040:4040/tcp --link mongodb emblica/halti-server",
            "title": "Master"
        },
        {
            "location": "/installation/#worker",
            "text": "Each worker node must have halti-agent running on. Halti agent takes care of the container management.  Halti-agent is stateless but it's recommended to mount volume for production usage so the state won't clutter with dead instances/hosts if container restarts by version upgrade or so.  PORT_BIND_IP  is special environment variable for the agent it will bind the services to.  It must be accessible from the loadbalancing edge nodes so it usually is the LAN-address of the halti worker machine.  docker run -d --restart=always --privileged -v /var/run/docker.sock:/var/run/docker.sock -e DOCKER_HOST=unix:///var/run/docker.sock -e HALTI_SERVER=https://halti-master-address:4040 -e PORT_BIND_IP=192.168.1.100 emblica/halti-agent",
            "title": "Worker"
        },
        {
            "location": "/installation/#luotsi-loadbalancing",
            "text": "Usually all halti worker nodes are also edge nodes but that is not a requirement.  Luotsi has following dependencies:\n- latest stable Haproxy\n- latest stable Node.js",
            "title": "Luotsi - loadbalancing"
        },
        {
            "location": "/installation/#installing-luotsi",
            "text": "git clone https://github.com/emblica/luotsi.git\ncd luotsi\n# Install dependencies\nnpm install",
            "title": "Installing luotsi"
        },
        {
            "location": "/installation/#running-luotsi",
            "text": "Before luotsi can be run you must first setup all the needed environment variables:  SSL_ENABLED=true/false\nCERT_PATH=absolute path to certificate pem\nMAINTENANCE_PAGE=absolute path to haproxy compatible maintenance page\nSTATS_USER=username of haproxy status web gui\nSTATS_PASS=password of haproxy status web guy\nHALTI_URL=url of the halti master  After environment variables are set just  node luotsi.js",
            "title": "Running luotsi"
        },
        {
            "location": "/scheduler/",
            "text": "Scheduling in Halti\n\n\nScheduler is pure function described in \nhalti-server.scheduler\n\n\nScheduling will take hosts and services in creation order in and schedule them with following rules:\n\n\n\n\nMultiple each service by it's replication factor \n(instances)\n\n\nMake sure no single host has two copies of the same service running\n\n\nMake sure that the host has \ncapabilities\n the service is \nrequiring\n\n\nMake sure we don't overprovision hosts \nmemory\n (so that the service has as much as memory it requires)\n\n\nMake sure we don't overprovision hosts \ncpu\n (so that the service has as much as CPU it requires)\n\n\n\n\nScheduler will run each of those services and try to assign all of them to each node and if it will find suitable one it will \nassign\n it to that instance. Otherwise the scheduler is trying to report to reason why some certain service instance isnt scheduled.",
            "title": "Scheduler"
        },
        {
            "location": "/scheduler/#scheduling-in-halti",
            "text": "Scheduler is pure function described in  halti-server.scheduler  Scheduling will take hosts and services in creation order in and schedule them with following rules:   Multiple each service by it's replication factor  (instances)  Make sure no single host has two copies of the same service running  Make sure that the host has  capabilities  the service is  requiring  Make sure we don't overprovision hosts  memory  (so that the service has as much as memory it requires)  Make sure we don't overprovision hosts  cpu  (so that the service has as much as CPU it requires)   Scheduler will run each of those services and try to assign all of them to each node and if it will find suitable one it will  assign  it to that instance. Otherwise the scheduler is trying to report to reason why some certain service instance isnt scheduled.",
            "title": "Scheduling in Halti"
        },
        {
            "location": "/API/hosts/",
            "text": "Hosts / Instances\n\n\n\n\n\n\n\n\nCollection\n\n\nBase URL\n\n\nFormat\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nHosts\n\n\n/api/v1/instances\n\n\nJSON\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nList All Hosts\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nGET\n\n\nJSON\n\n\n200\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\n{\n  \"instances\": [\n    {\n      \"config\": {\n        \"containers\": [\n          \"c01d84bc-31f8-4357-8754-c60ec323d321\",\n          \"bc922611-bfd1-44cb-8d8a-09148df0009a\",\n          \"e8bfbb9d-4b0d-40b9-94ac-d509d116ee3c\"\n        ]\n      },\n      \"last_heartbeat\": \"2016-04-11T22:12:13.293+03:00\",\n      \"capabilities\": [\"SSD\", \"INTRANET\"],\n      \"containers\": [],\n      \"created\": \"2016-04-11T22:12:03.234+03:00\",\n      \"instance_id\": \"d107ce15-db80-40fc-828c-edcb9fa79028\",\n      \"system\": {\n        \"system\": \"Darwin\",\n        \"cpus\": 8,\n        \"system_version\": \"Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64\",\n        \"hostname\": \"L760\"\n      },\n      \"client\": {\n        \"GoVersion\": \"go1.4.2\",\n        \"Arch\": \"amd64\",\n        \"GitCommit\": \"d12ea79\",\n        \"Version\": \"1.8.1\",\n        \"ApiVersion\": \"1.20\",\n        \"BuildTime\": \"Thu Aug 13 02:49:29 UTC 2015\",\n        \"Os\": \"linux\",\n        \"KernelVersion\": \"4.0.9-boot2docker\"\n      },\n      \"info\": {\n        \"ID\": \"ZKFK:FH64:SML4:IH6B:PEIX:XPKL:D4Y5:7U57:QITU:D7L2:D6LW:BYWW\",\n        \"MemTotal\": 2099998720,\n        \"BridgeNfIptables\": true,\n        \"DriverStatus\": [\n          [\n            \"Root Dir\",\n            \"/mnt/sda1/var/lib/docker/aufs\"\n          ],\n          [\n            \"Backing Filesystem\",\n            \"extfs\"\n          ],\n          [\n            \"Dirs\",\n            \"39\"\n          ],\n          [\n            \"Dirperm1 Supported\",\n            \"true\"\n          ]\n        ],\n        \"Labels\": [\n          \"provider=virtualbox\"\n        ],\n        \"Driver\": \"aufs\",\n        \"LoggingDriver\": \"json-file\",\n        \"NFd\": 23,\n        \"CpuCfsQuota\": true,\n        \"NGoroutines\": 54,\n        \"Images\": 35,\n        \"Containers\": 2,\n        \"ExperimentalBuild\": false,\n        \"InitSha1\": \"\",\n        \"IndexServerAddress\": \"https://index.docker.io/v1/\",\n        \"SystemTime\": \"2016-04-11T19:12:03.240898323Z\",\n        \"HttpsProxy\": \"\",\n        \"ExecutionDriver\": \"native-0.2\",\n        \"SwapLimit\": true,\n        \"Debug\": true,\n        \"KernelVersion\": \"4.0.9-boot2docker\",\n        \"NEventsListener\": 1,\n        \"MemoryLimit\": true,\n        \"BridgeNfIp6tables\": true,\n        \"OomKillDisable\": true,\n        \"Name\": \"default\",\n        \"NoProxy\": \"\",\n        \"InitPath\": \"/usr/local/bin/docker\",\n        \"OperatingSystem\": \"Boot2Docker 1.8.1 (TCL 6.3); master : 7f12e95 - Thu Aug 13 03:24:56 UTC 2015\",\n        \"IPv4Forwarding\": true,\n        \"NCPU\": 1,\n        \"CpuCfsPeriod\": true,\n        \"DockerRootDir\": \"/mnt/sda1/var/lib/docker\",\n        \"HttpProxy\": \"\"\n      }\n    },\n    {\n      \"config\": {\n        \"containers\": [\n          \"c01d84bc-31f8-4357-8754-c60ec323d321\",\n          \"bc922611-bfd1-44cb-8d8a-09148df0009a\",\n          \"e8bfbb9d-4b0d-40b9-94ac-d509d116ee3c\"\n        ]\n      },\n      \"last_heartbeat\": \"2016-04-11T22:14:43.978+03:00\",\n      \"containers\": [],\n      \"created\": \"2016-04-11T22:12:23.605+03:00\",\n      \"instance_id\": \"114d4230-bcbc-47b1-97ef-c7ffff39297b\",\n      \"system\": {\n        \"system\": \"Darwin\",\n        \"cpus\": 8,\n        \"system_version\": \"Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64\",\n        \"hostname\": \"L760\"\n      },\n      \"client\": {\n        \"GoVersion\": \"go1.4.2\",\n        \"Arch\": \"amd64\",\n        \"GitCommit\": \"d12ea79\",\n        \"Version\": \"1.8.1\",\n        \"ApiVersion\": \"1.20\",\n        \"BuildTime\": \"Thu Aug 13 02:49:29 UTC 2015\",\n        \"Os\": \"linux\",\n        \"KernelVersion\": \"4.0.9-boot2docker\"\n      },\n      \"info\": {\n        \"ID\": \"ZKFK:FH64:SML4:IH6B:PEIX:XPKL:D4Y5:7U57:QITU:D7L2:D6LW:BYWW\",\n        \"MemTotal\": 2099998720,\n        \"BridgeNfIptables\": true,\n        \"DriverStatus\": [\n          [\n            \"Root Dir\",\n            \"/mnt/sda1/var/lib/docker/aufs\"\n          ],\n          [\n            \"Backing Filesystem\",\n            \"extfs\"\n          ],\n          [\n            \"Dirs\",\n            \"39\"\n          ],\n          [\n            \"Dirperm1 Supported\",\n            \"true\"\n          ]\n        ],\n        \"Labels\": [\n          \"provider=virtualbox\"\n        ],\n        \"Driver\": \"aufs\",\n        \"LoggingDriver\": \"json-file\",\n        \"NFd\": 23,\n        \"CpuCfsQuota\": true,\n        \"NGoroutines\": 54,\n        \"Images\": 35,\n        \"Containers\": 2,\n        \"ExperimentalBuild\": false,\n        \"InitSha1\": \"\",\n        \"IndexServerAddress\": \"https://index.docker.io/v1/\",\n        \"SystemTime\": \"2016-04-11T19:12:23.611537998Z\",\n        \"HttpsProxy\": \"\",\n        \"ExecutionDriver\": \"native-0.2\",\n        \"SwapLimit\": true,\n        \"Debug\": true,\n        \"KernelVersion\": \"4.0.9-boot2docker\",\n        \"NEventsListener\": 1,\n        \"MemoryLimit\": true,\n        \"BridgeNfIp6tables\": true,\n        \"OomKillDisable\": true,\n        \"Name\": \"default\",\n        \"NoProxy\": \"\",\n        \"InitPath\": \"/usr/local/bin/docker\",\n        \"OperatingSystem\": \"Boot2Docker 1.8.1 (TCL 6.3); master : 7f12e95 - Thu Aug 13 03:24:56 UTC 2015\",\n        \"IPv4Forwarding\": true,\n        \"NCPU\": 1,\n        \"CpuCfsPeriod\": true,\n        \"DockerRootDir\": \"/mnt/sda1/var/lib/docker\",\n        \"HttpProxy\": \"\"\n      }\n    },\n    {\n      \"config\": {\n        \"containers\": [\n          \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n          \"5a1496e6-13e8-444e-a2ad-3f740a1be837\"\n        ]\n      },\n      \"last_heartbeat\": \"2016-04-13T09:57:07.311+03:00\",\n      \"containers\": [\n        {\n          \"Status\": \"Up 3 hours\",\n          \"Created\": 1460502282,\n          \"Names\": [\n            \"/5a1496e6-13e8-444e-a2ad-3f740a1be837\"\n          ],\n          \"Command\": \"/bin/sh -c 'php-fpm -d variables_order=\\\"EGPCS\\\" && (tail -F /var/log/nginx/access.log &) && exec nginx -g \\\"daemon off;\\\"'\",\n          \"HostConfig\": {\n            \"NetworkMode\": \"default\"\n          },\n          \"Id\": \"c777cca181d57c30910a42a13acf227da8b0b107aa351e378840cbdd98620c9c\",\n          \"Labels\": {\n            \"halti\": \"true\",\n            \"version\": \"hello1\",\n            \"service\": \"hello-world8000\"\n          },\n          \"Image\": \"tutum/hello-world\",\n          \"Ports\": [\n            {\n              \"PublicPort\": 32824,\n              \"IP\": \"192.168.99.100\",\n              \"PrivatePort\": 8080,\n              \"Type\": \"tcp\"\n            },\n            {\n              \"PublicPort\": 32825,\n              \"IP\": \"192.168.99.100\",\n              \"PrivatePort\": 80,\n              \"Type\": \"tcp\"\n            }\n          ]\n        },\n        {\n          \"Status\": \"Up 3 hours\",\n          \"Created\": 1460502279,\n          \"Names\": [\n            \"/ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\"\n          ],\n          \"Command\": \"/bin/sh -c 'php-fpm -d variables_order=\\\"EGPCS\\\" && (tail -F /var/log/nginx/access.log &) && exec nginx -g \\\"daemon off;\\\"'\",\n          \"HostConfig\": {\n            \"NetworkMode\": \"default\"\n          },\n          \"Id\": \"c68436022a14755a581b010f613b0ca463b81a552f59bfda0200ec444eb5dcef\",\n          \"Labels\": {\n            \"halti\": \"true\",\n            \"version\": \"hello4\",\n            \"service\": \"hello-world3\"\n          },\n          \"Image\": \"tutum/hello-world\",\n          \"Ports\": [\n            {\n              \"PublicPort\": 32823,\n              \"IP\": \"192.168.99.100\",\n              \"PrivatePort\": 80,\n              \"Type\": \"tcp\"\n            }\n          ]\n        }\n      ],\n      \"created\": \"2016-04-11T22:14:47.316+03:00\",\n      \"instance_id\": \"c0bb9dc2-6c99-4c1b-9662-0602abbce695\",\n      \"system\": {\n        \"system\": \"Darwin\",\n        \"cpus\": 8,\n        \"system_version\": \"Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64\",\n        \"hostname\": \"L760\"\n      },\n      \"client\": {\n        \"GoVersion\": \"go1.4.2\",\n        \"Arch\": \"amd64\",\n        \"GitCommit\": \"d12ea79\",\n        \"Version\": \"1.8.1\",\n        \"ApiVersion\": \"1.20\",\n        \"BuildTime\": \"Thu Aug 13 02:49:29 UTC 2015\",\n        \"Os\": \"linux\",\n        \"KernelVersion\": \"4.0.9-boot2docker\"\n      },\n      \"info\": {\n        \"ID\": \"ZKFK:FH64:SML4:IH6B:PEIX:XPKL:D4Y5:7U57:QITU:D7L2:D6LW:BYWW\",\n        \"MemTotal\": 2099998720,\n        \"BridgeNfIptables\": true,\n        \"DriverStatus\": [\n          [\n            \"Root Dir\",\n            \"/mnt/sda1/var/lib/docker/aufs\"\n          ],\n          [\n            \"Backing Filesystem\",\n            \"extfs\"\n          ],\n          [\n            \"Dirs\",\n            \"39\"\n          ],\n          [\n            \"Dirperm1 Supported\",\n            \"true\"\n          ]\n        ],\n        \"Labels\": [\n          \"provider=virtualbox\"\n        ],\n        \"Driver\": \"aufs\",\n        \"LoggingDriver\": \"json-file\",\n        \"NFd\": 23,\n        \"CpuCfsQuota\": true,\n        \"NGoroutines\": 54,\n        \"Images\": 35,\n        \"Containers\": 2,\n        \"ExperimentalBuild\": false,\n        \"InitSha1\": \"\",\n        \"IndexServerAddress\": \"https://index.docker.io/v1/\",\n        \"SystemTime\": \"2016-04-11T19:14:47.323625842Z\",\n        \"HttpsProxy\": \"\",\n        \"ExecutionDriver\": \"native-0.2\",\n        \"SwapLimit\": true,\n        \"Debug\": true,\n        \"KernelVersion\": \"4.0.9-boot2docker\",\n        \"NEventsListener\": 1,\n        \"MemoryLimit\": true,\n        \"BridgeNfIp6tables\": true,\n        \"OomKillDisable\": true,\n        \"Name\": \"default\",\n        \"NoProxy\": \"\",\n        \"InitPath\": \"/usr/local/bin/docker\",\n        \"OperatingSystem\": \"Boot2Docker 1.8.1 (TCL 6.3); master : 7f12e95 - Thu Aug 13 03:24:56 UTC 2015\",\n        \"IPv4Forwarding\": true,\n        \"NCPU\": 1,\n        \"CpuCfsPeriod\": true,\n        \"DockerRootDir\": \"/mnt/sda1/var/lib/docker\",\n        \"HttpProxy\": \"\"\n      }\n    }\n  ]\n}\n\n\n\n\n\nHealthy Hosts / Instances\n\n\n\n\n\n\n\n\nCollection\n\n\nBase URL\n\n\nFormat\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nHealthy Hosts\n\n\n/api/v1/instances/healthy\n\n\nJSON\n\n\n-\n\n\nShows only currently active hosts of the cluster\n\n\n\n\n\n\n\n\nList All Healthy Hosts\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nGET\n\n\nJSON\n\n\n200\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\n{\n  \"instances\": [{\n      \"config\": {\n        \"containers\": [\n          \"c01d84bc-31f8-4357-8754-c60ec323d321\",\n          \"bc922611-bfd1-44cb-8d8a-09148df0009a\",\n          \"e8bfbb9d-4b0d-40b9-94ac-d509d116ee3c\"\n        ]\n      },\n      \"last_heartbeat\": \"2016-04-11T22:12:13.293+03:00\",\n      \"containers\": [],\n      \"capabilities\": [\"SSD\", \"INTRANET\"],\n      \"created\": \"2016-04-11T22:12:03.234+03:00\",\n      \"instance_id\": \"d107ce15-db80-40fc-828c-edcb9fa79028\",\n      \"system\": {\n        \"system\": \"Darwin\",\n        \"cpus\": 8,\n        \"system_version\": \"Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64\",\n        \"hostname\": \"L760\"\n      },\n      \"client\": {\n        \"GoVersion\": \"go1.4.2\",\n        \"Arch\": \"amd64\",\n        \"GitCommit\": \"d12ea79\",\n        \"Version\": \"1.8.1\",\n        \"ApiVersion\": \"1.20\",\n        \"BuildTime\": \"Thu Aug 13 02:49:29 UTC 2015\",\n        \"Os\": \"linux\",\n        \"KernelVersion\": \"4.0.9-boot2docker\"\n      },\n      \"info\": {\n        \"ID\": \"ZKFK:FH64:SML4:IH6B:PEIX:XPKL:D4Y5:7U57:QITU:D7L2:D6LW:BYWW\",\n        \"MemTotal\": 2099998720,\n        \"BridgeNfIptables\": true,\n        \"DriverStatus\": [\n          [\n            \"Root Dir\",\n            \"/mnt/sda1/var/lib/docker/aufs\"\n          ],\n          [\n            \"Backing Filesystem\",\n            \"extfs\"\n          ],\n          [\n            \"Dirs\",\n            \"39\"\n          ],\n          [\n            \"Dirperm1 Supported\",\n            \"true\"\n          ]\n        ],\n        \"Labels\": [\n          \"provider=virtualbox\"\n        ],\n        \"Driver\": \"aufs\",\n        \"LoggingDriver\": \"json-file\",\n        \"NFd\": 23,\n        \"CpuCfsQuota\": true,\n        \"NGoroutines\": 54,\n        \"Images\": 35,\n        \"Containers\": 2,\n        \"ExperimentalBuild\": false,\n        \"InitSha1\": \"\",\n        \"IndexServerAddress\": \"https://index.docker.io/v1/\",\n        \"SystemTime\": \"2016-04-11T19:12:03.240898323Z\",\n        \"HttpsProxy\": \"\",\n        \"ExecutionDriver\": \"native-0.2\",\n        \"SwapLimit\": true,\n        \"Debug\": true,\n        \"KernelVersion\": \"4.0.9-boot2docker\",\n        \"NEventsListener\": 1,\n        \"MemoryLimit\": true,\n        \"BridgeNfIp6tables\": true,\n        \"OomKillDisable\": true,\n        \"Name\": \"default\",\n        \"NoProxy\": \"\",\n        \"InitPath\": \"/usr/local/bin/docker\",\n        \"OperatingSystem\": \"Boot2Docker 1.8.1 (TCL 6.3); master : 7f12e95 - Thu Aug 13 03:24:56 UTC 2015\",\n        \"IPv4Forwarding\": true,\n        \"NCPU\": 1,\n        \"CpuCfsPeriod\": true,\n        \"DockerRootDir\": \"/mnt/sda1/var/lib/docker\",\n        \"HttpProxy\": \"\"\n      }\n    }]\n}",
            "title": "Hosts"
        },
        {
            "location": "/API/hosts/#hosts-instances",
            "text": "Collection  Base URL  Format  Stability  Additional information      Hosts  /api/v1/instances  JSON  -  -",
            "title": "Hosts / Instances"
        },
        {
            "location": "/API/hosts/#list-all-hosts",
            "text": "Method  Format  Response Status (OK)  Stability  Additional information      GET  JSON  200  -  -     {\n  \"instances\": [\n    {\n      \"config\": {\n        \"containers\": [\n          \"c01d84bc-31f8-4357-8754-c60ec323d321\",\n          \"bc922611-bfd1-44cb-8d8a-09148df0009a\",\n          \"e8bfbb9d-4b0d-40b9-94ac-d509d116ee3c\"\n        ]\n      },\n      \"last_heartbeat\": \"2016-04-11T22:12:13.293+03:00\",\n      \"capabilities\": [\"SSD\", \"INTRANET\"],\n      \"containers\": [],\n      \"created\": \"2016-04-11T22:12:03.234+03:00\",\n      \"instance_id\": \"d107ce15-db80-40fc-828c-edcb9fa79028\",\n      \"system\": {\n        \"system\": \"Darwin\",\n        \"cpus\": 8,\n        \"system_version\": \"Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64\",\n        \"hostname\": \"L760\"\n      },\n      \"client\": {\n        \"GoVersion\": \"go1.4.2\",\n        \"Arch\": \"amd64\",\n        \"GitCommit\": \"d12ea79\",\n        \"Version\": \"1.8.1\",\n        \"ApiVersion\": \"1.20\",\n        \"BuildTime\": \"Thu Aug 13 02:49:29 UTC 2015\",\n        \"Os\": \"linux\",\n        \"KernelVersion\": \"4.0.9-boot2docker\"\n      },\n      \"info\": {\n        \"ID\": \"ZKFK:FH64:SML4:IH6B:PEIX:XPKL:D4Y5:7U57:QITU:D7L2:D6LW:BYWW\",\n        \"MemTotal\": 2099998720,\n        \"BridgeNfIptables\": true,\n        \"DriverStatus\": [\n          [\n            \"Root Dir\",\n            \"/mnt/sda1/var/lib/docker/aufs\"\n          ],\n          [\n            \"Backing Filesystem\",\n            \"extfs\"\n          ],\n          [\n            \"Dirs\",\n            \"39\"\n          ],\n          [\n            \"Dirperm1 Supported\",\n            \"true\"\n          ]\n        ],\n        \"Labels\": [\n          \"provider=virtualbox\"\n        ],\n        \"Driver\": \"aufs\",\n        \"LoggingDriver\": \"json-file\",\n        \"NFd\": 23,\n        \"CpuCfsQuota\": true,\n        \"NGoroutines\": 54,\n        \"Images\": 35,\n        \"Containers\": 2,\n        \"ExperimentalBuild\": false,\n        \"InitSha1\": \"\",\n        \"IndexServerAddress\": \"https://index.docker.io/v1/\",\n        \"SystemTime\": \"2016-04-11T19:12:03.240898323Z\",\n        \"HttpsProxy\": \"\",\n        \"ExecutionDriver\": \"native-0.2\",\n        \"SwapLimit\": true,\n        \"Debug\": true,\n        \"KernelVersion\": \"4.0.9-boot2docker\",\n        \"NEventsListener\": 1,\n        \"MemoryLimit\": true,\n        \"BridgeNfIp6tables\": true,\n        \"OomKillDisable\": true,\n        \"Name\": \"default\",\n        \"NoProxy\": \"\",\n        \"InitPath\": \"/usr/local/bin/docker\",\n        \"OperatingSystem\": \"Boot2Docker 1.8.1 (TCL 6.3); master : 7f12e95 - Thu Aug 13 03:24:56 UTC 2015\",\n        \"IPv4Forwarding\": true,\n        \"NCPU\": 1,\n        \"CpuCfsPeriod\": true,\n        \"DockerRootDir\": \"/mnt/sda1/var/lib/docker\",\n        \"HttpProxy\": \"\"\n      }\n    },\n    {\n      \"config\": {\n        \"containers\": [\n          \"c01d84bc-31f8-4357-8754-c60ec323d321\",\n          \"bc922611-bfd1-44cb-8d8a-09148df0009a\",\n          \"e8bfbb9d-4b0d-40b9-94ac-d509d116ee3c\"\n        ]\n      },\n      \"last_heartbeat\": \"2016-04-11T22:14:43.978+03:00\",\n      \"containers\": [],\n      \"created\": \"2016-04-11T22:12:23.605+03:00\",\n      \"instance_id\": \"114d4230-bcbc-47b1-97ef-c7ffff39297b\",\n      \"system\": {\n        \"system\": \"Darwin\",\n        \"cpus\": 8,\n        \"system_version\": \"Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64\",\n        \"hostname\": \"L760\"\n      },\n      \"client\": {\n        \"GoVersion\": \"go1.4.2\",\n        \"Arch\": \"amd64\",\n        \"GitCommit\": \"d12ea79\",\n        \"Version\": \"1.8.1\",\n        \"ApiVersion\": \"1.20\",\n        \"BuildTime\": \"Thu Aug 13 02:49:29 UTC 2015\",\n        \"Os\": \"linux\",\n        \"KernelVersion\": \"4.0.9-boot2docker\"\n      },\n      \"info\": {\n        \"ID\": \"ZKFK:FH64:SML4:IH6B:PEIX:XPKL:D4Y5:7U57:QITU:D7L2:D6LW:BYWW\",\n        \"MemTotal\": 2099998720,\n        \"BridgeNfIptables\": true,\n        \"DriverStatus\": [\n          [\n            \"Root Dir\",\n            \"/mnt/sda1/var/lib/docker/aufs\"\n          ],\n          [\n            \"Backing Filesystem\",\n            \"extfs\"\n          ],\n          [\n            \"Dirs\",\n            \"39\"\n          ],\n          [\n            \"Dirperm1 Supported\",\n            \"true\"\n          ]\n        ],\n        \"Labels\": [\n          \"provider=virtualbox\"\n        ],\n        \"Driver\": \"aufs\",\n        \"LoggingDriver\": \"json-file\",\n        \"NFd\": 23,\n        \"CpuCfsQuota\": true,\n        \"NGoroutines\": 54,\n        \"Images\": 35,\n        \"Containers\": 2,\n        \"ExperimentalBuild\": false,\n        \"InitSha1\": \"\",\n        \"IndexServerAddress\": \"https://index.docker.io/v1/\",\n        \"SystemTime\": \"2016-04-11T19:12:23.611537998Z\",\n        \"HttpsProxy\": \"\",\n        \"ExecutionDriver\": \"native-0.2\",\n        \"SwapLimit\": true,\n        \"Debug\": true,\n        \"KernelVersion\": \"4.0.9-boot2docker\",\n        \"NEventsListener\": 1,\n        \"MemoryLimit\": true,\n        \"BridgeNfIp6tables\": true,\n        \"OomKillDisable\": true,\n        \"Name\": \"default\",\n        \"NoProxy\": \"\",\n        \"InitPath\": \"/usr/local/bin/docker\",\n        \"OperatingSystem\": \"Boot2Docker 1.8.1 (TCL 6.3); master : 7f12e95 - Thu Aug 13 03:24:56 UTC 2015\",\n        \"IPv4Forwarding\": true,\n        \"NCPU\": 1,\n        \"CpuCfsPeriod\": true,\n        \"DockerRootDir\": \"/mnt/sda1/var/lib/docker\",\n        \"HttpProxy\": \"\"\n      }\n    },\n    {\n      \"config\": {\n        \"containers\": [\n          \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n          \"5a1496e6-13e8-444e-a2ad-3f740a1be837\"\n        ]\n      },\n      \"last_heartbeat\": \"2016-04-13T09:57:07.311+03:00\",\n      \"containers\": [\n        {\n          \"Status\": \"Up 3 hours\",\n          \"Created\": 1460502282,\n          \"Names\": [\n            \"/5a1496e6-13e8-444e-a2ad-3f740a1be837\"\n          ],\n          \"Command\": \"/bin/sh -c 'php-fpm -d variables_order=\\\"EGPCS\\\" && (tail -F /var/log/nginx/access.log &) && exec nginx -g \\\"daemon off;\\\"'\",\n          \"HostConfig\": {\n            \"NetworkMode\": \"default\"\n          },\n          \"Id\": \"c777cca181d57c30910a42a13acf227da8b0b107aa351e378840cbdd98620c9c\",\n          \"Labels\": {\n            \"halti\": \"true\",\n            \"version\": \"hello1\",\n            \"service\": \"hello-world8000\"\n          },\n          \"Image\": \"tutum/hello-world\",\n          \"Ports\": [\n            {\n              \"PublicPort\": 32824,\n              \"IP\": \"192.168.99.100\",\n              \"PrivatePort\": 8080,\n              \"Type\": \"tcp\"\n            },\n            {\n              \"PublicPort\": 32825,\n              \"IP\": \"192.168.99.100\",\n              \"PrivatePort\": 80,\n              \"Type\": \"tcp\"\n            }\n          ]\n        },\n        {\n          \"Status\": \"Up 3 hours\",\n          \"Created\": 1460502279,\n          \"Names\": [\n            \"/ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\"\n          ],\n          \"Command\": \"/bin/sh -c 'php-fpm -d variables_order=\\\"EGPCS\\\" && (tail -F /var/log/nginx/access.log &) && exec nginx -g \\\"daemon off;\\\"'\",\n          \"HostConfig\": {\n            \"NetworkMode\": \"default\"\n          },\n          \"Id\": \"c68436022a14755a581b010f613b0ca463b81a552f59bfda0200ec444eb5dcef\",\n          \"Labels\": {\n            \"halti\": \"true\",\n            \"version\": \"hello4\",\n            \"service\": \"hello-world3\"\n          },\n          \"Image\": \"tutum/hello-world\",\n          \"Ports\": [\n            {\n              \"PublicPort\": 32823,\n              \"IP\": \"192.168.99.100\",\n              \"PrivatePort\": 80,\n              \"Type\": \"tcp\"\n            }\n          ]\n        }\n      ],\n      \"created\": \"2016-04-11T22:14:47.316+03:00\",\n      \"instance_id\": \"c0bb9dc2-6c99-4c1b-9662-0602abbce695\",\n      \"system\": {\n        \"system\": \"Darwin\",\n        \"cpus\": 8,\n        \"system_version\": \"Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64\",\n        \"hostname\": \"L760\"\n      },\n      \"client\": {\n        \"GoVersion\": \"go1.4.2\",\n        \"Arch\": \"amd64\",\n        \"GitCommit\": \"d12ea79\",\n        \"Version\": \"1.8.1\",\n        \"ApiVersion\": \"1.20\",\n        \"BuildTime\": \"Thu Aug 13 02:49:29 UTC 2015\",\n        \"Os\": \"linux\",\n        \"KernelVersion\": \"4.0.9-boot2docker\"\n      },\n      \"info\": {\n        \"ID\": \"ZKFK:FH64:SML4:IH6B:PEIX:XPKL:D4Y5:7U57:QITU:D7L2:D6LW:BYWW\",\n        \"MemTotal\": 2099998720,\n        \"BridgeNfIptables\": true,\n        \"DriverStatus\": [\n          [\n            \"Root Dir\",\n            \"/mnt/sda1/var/lib/docker/aufs\"\n          ],\n          [\n            \"Backing Filesystem\",\n            \"extfs\"\n          ],\n          [\n            \"Dirs\",\n            \"39\"\n          ],\n          [\n            \"Dirperm1 Supported\",\n            \"true\"\n          ]\n        ],\n        \"Labels\": [\n          \"provider=virtualbox\"\n        ],\n        \"Driver\": \"aufs\",\n        \"LoggingDriver\": \"json-file\",\n        \"NFd\": 23,\n        \"CpuCfsQuota\": true,\n        \"NGoroutines\": 54,\n        \"Images\": 35,\n        \"Containers\": 2,\n        \"ExperimentalBuild\": false,\n        \"InitSha1\": \"\",\n        \"IndexServerAddress\": \"https://index.docker.io/v1/\",\n        \"SystemTime\": \"2016-04-11T19:14:47.323625842Z\",\n        \"HttpsProxy\": \"\",\n        \"ExecutionDriver\": \"native-0.2\",\n        \"SwapLimit\": true,\n        \"Debug\": true,\n        \"KernelVersion\": \"4.0.9-boot2docker\",\n        \"NEventsListener\": 1,\n        \"MemoryLimit\": true,\n        \"BridgeNfIp6tables\": true,\n        \"OomKillDisable\": true,\n        \"Name\": \"default\",\n        \"NoProxy\": \"\",\n        \"InitPath\": \"/usr/local/bin/docker\",\n        \"OperatingSystem\": \"Boot2Docker 1.8.1 (TCL 6.3); master : 7f12e95 - Thu Aug 13 03:24:56 UTC 2015\",\n        \"IPv4Forwarding\": true,\n        \"NCPU\": 1,\n        \"CpuCfsPeriod\": true,\n        \"DockerRootDir\": \"/mnt/sda1/var/lib/docker\",\n        \"HttpProxy\": \"\"\n      }\n    }\n  ]\n}",
            "title": "List All Hosts"
        },
        {
            "location": "/API/hosts/#healthy-hosts-instances",
            "text": "Collection  Base URL  Format  Stability  Additional information      Healthy Hosts  /api/v1/instances/healthy  JSON  -  Shows only currently active hosts of the cluster",
            "title": "Healthy Hosts / Instances"
        },
        {
            "location": "/API/hosts/#list-all-healthy-hosts",
            "text": "Method  Format  Response Status (OK)  Stability  Additional information      GET  JSON  200  -  -     {\n  \"instances\": [{\n      \"config\": {\n        \"containers\": [\n          \"c01d84bc-31f8-4357-8754-c60ec323d321\",\n          \"bc922611-bfd1-44cb-8d8a-09148df0009a\",\n          \"e8bfbb9d-4b0d-40b9-94ac-d509d116ee3c\"\n        ]\n      },\n      \"last_heartbeat\": \"2016-04-11T22:12:13.293+03:00\",\n      \"containers\": [],\n      \"capabilities\": [\"SSD\", \"INTRANET\"],\n      \"created\": \"2016-04-11T22:12:03.234+03:00\",\n      \"instance_id\": \"d107ce15-db80-40fc-828c-edcb9fa79028\",\n      \"system\": {\n        \"system\": \"Darwin\",\n        \"cpus\": 8,\n        \"system_version\": \"Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64\",\n        \"hostname\": \"L760\"\n      },\n      \"client\": {\n        \"GoVersion\": \"go1.4.2\",\n        \"Arch\": \"amd64\",\n        \"GitCommit\": \"d12ea79\",\n        \"Version\": \"1.8.1\",\n        \"ApiVersion\": \"1.20\",\n        \"BuildTime\": \"Thu Aug 13 02:49:29 UTC 2015\",\n        \"Os\": \"linux\",\n        \"KernelVersion\": \"4.0.9-boot2docker\"\n      },\n      \"info\": {\n        \"ID\": \"ZKFK:FH64:SML4:IH6B:PEIX:XPKL:D4Y5:7U57:QITU:D7L2:D6LW:BYWW\",\n        \"MemTotal\": 2099998720,\n        \"BridgeNfIptables\": true,\n        \"DriverStatus\": [\n          [\n            \"Root Dir\",\n            \"/mnt/sda1/var/lib/docker/aufs\"\n          ],\n          [\n            \"Backing Filesystem\",\n            \"extfs\"\n          ],\n          [\n            \"Dirs\",\n            \"39\"\n          ],\n          [\n            \"Dirperm1 Supported\",\n            \"true\"\n          ]\n        ],\n        \"Labels\": [\n          \"provider=virtualbox\"\n        ],\n        \"Driver\": \"aufs\",\n        \"LoggingDriver\": \"json-file\",\n        \"NFd\": 23,\n        \"CpuCfsQuota\": true,\n        \"NGoroutines\": 54,\n        \"Images\": 35,\n        \"Containers\": 2,\n        \"ExperimentalBuild\": false,\n        \"InitSha1\": \"\",\n        \"IndexServerAddress\": \"https://index.docker.io/v1/\",\n        \"SystemTime\": \"2016-04-11T19:12:03.240898323Z\",\n        \"HttpsProxy\": \"\",\n        \"ExecutionDriver\": \"native-0.2\",\n        \"SwapLimit\": true,\n        \"Debug\": true,\n        \"KernelVersion\": \"4.0.9-boot2docker\",\n        \"NEventsListener\": 1,\n        \"MemoryLimit\": true,\n        \"BridgeNfIp6tables\": true,\n        \"OomKillDisable\": true,\n        \"Name\": \"default\",\n        \"NoProxy\": \"\",\n        \"InitPath\": \"/usr/local/bin/docker\",\n        \"OperatingSystem\": \"Boot2Docker 1.8.1 (TCL 6.3); master : 7f12e95 - Thu Aug 13 03:24:56 UTC 2015\",\n        \"IPv4Forwarding\": true,\n        \"NCPU\": 1,\n        \"CpuCfsPeriod\": true,\n        \"DockerRootDir\": \"/mnt/sda1/var/lib/docker\",\n        \"HttpProxy\": \"\"\n      }\n    }]\n}",
            "title": "List All Healthy Hosts"
        },
        {
            "location": "/API/loadbalancers/",
            "text": "Loadbalancers\n\n\n\n\n\n\n\n\nCollection\n\n\nBase URL\n\n\nFormat\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nLoadbalancers\n\n\n/api/v1/loadbalancers\n\n\nJSON\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nList All Loadbalancers\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nGET\n\n\nJSON\n\n\n200\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\n{\n  \"loadbalancers\": [\n    {\n      \"ports\": {\n        \"https\": true,\n        \"http\": true\n      },\n      \"force_https\": false,\n      \"source_port\": 80,\n      \"network\": \"172.16.0.0/12 80.69.169.128/26\",\n      \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n      \"hostname\": \"hello.slush.org\",\n      \"enabled\": true,\n      \"name\": \"hello-world\",\n      \"loadbalancer_id\": \"0308e104-adc2-4868-b154-d42cf75a720c\"\n    },\n    {\n      \"ports\": {\n        \"https\": false,\n        \"http\": true\n      },\n      \"force_https\": false,\n      \"source_port\": 80,\n      \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n      \"hostname\": \"hello2.slush.org\",\n      \"enabled\": true,\n      \"name\": \"hello-world2\",\n      \"loadbalancer_id\": \"a4ec5443-9a12-4fec-96b1-92bb2c2c6eb5\"\n    },\n    {\n      \"ports\": {\n        \"https\": false,\n        \"http\": true\n      },\n      \"force_https\": false,\n      \"source_port\": 8080,\n      \"service_id\": \"5a1496e6-13e8-444e-a2ad-3f740a1be837\",\n      \"hostname\": \"hello3.slush.org\",\n      \"enabled\": true,\n      \"name\": \"hello-world3\",\n      \"loadbalancer_id\": \"1c53a7e4-d9ce-4b19-ac39-167dd80aca50\"\n    }\n  ]\n}\n\n\n\n\nCreate a New Loadbalancer\n\n\nCreating new loadbalancer takes name, hostname, service_id for service to be loadbalancer and source port of the service\nThere is also optional \nnetwork\n argument, you can use it to limit the source address of incoming requests.\nUsed for example with internal services.\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nPOST\n\n\nJSON\n\n\n201\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nRequest\n\n\n{\n    \"name\": \"hello-world2\",\n    \"enabled\": true,\n    \"hostname\": \"hello2.slush.org\",\n    \"network\": \"172.16.0.0/12\",\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"source_port\": 80,\n    \"force_https\": false,\n    \"ports\": {\"http\": true, \"https\": false}\n}\n\n\n\n\nResponse\n\n\n{\n  \"loadbalancer\": {\n    \"loadbalancer_id\": \"229b7a00-85d1-4f23-9238-277bc9d25337\",\n    \"name\": \"hello-world2\",\n    \"enabled\": true,\n    \"hostname\": \"hello2.slush.org\",\n    \"network\": \"172.16.0.0/12\",\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"source_port\": 80,\n    \"force_https\": false,\n    \"ports\": {\n      \"http\": true,\n      \"https\": false\n    }\n  }\n}\n\n\n\n\nSingle loadbalancer\n\n\n\n\n\n\n\n\nCollection\n\n\nBase URL\n\n\nFormat\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nSingle loadbalancer\n\n\n/api/v1/loadbalancers/{loadbalancer_id}\n\n\nJSON\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nRead Loadbalancer\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nGET\n\n\nJSON\n\n\n200\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\n{\n  \"loadbalancer\": {\n    \"ports\": {\n      \"https\": false,\n      \"http\": true\n    },\n    \"force_https\": false,\n    \"source_port\": 80,\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"hostname\": \"hello2.slush.org\",\n    \"network\": \"172.16.0.0/12 80.69.169.128/26\",\n    \"enabled\": true,\n    \"name\": \"hello-world2\",\n    \"loadbalancer_id\": \"229b7a00-85d1-4f23-9238-277bc9d25337\"\n  }\n}\n\n\n\n\nUpdate Loadbalancer\n\n\nThis is partial operation and you can just PUT different fields.\nChanges are merged in server and returned the full document\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nPUT\n\n\nJSON\n\n\n200\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nRequest\n\n\n{\n    \"force_https\": true\n}\n\n\n\n\nResponse\n\n\n\n{\n  \"loadbalancer\": {\n    \"ports\": {\n      \"https\": false,\n      \"http\": true\n    },\n    \"force_https\": true,\n    \"source_port\": 80,\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"hostname\": \"hello2.slush.org\",\n    \"enabled\": true,\n    \"name\": \"hello-world2\",\n    \"loadbalancer_id\": \"229b7a00-85d1-4f23-9238-277bc9d25337\"\n  }\n}\n\n\n\n\nLoadbalancer configuration\n\n\n\n\n\n\n\n\nCollection\n\n\nBase URL\n\n\nFormat\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nLoadbalancer config\n\n\n/api/v1/loadbalancers/config\n\n\nJSON\n\n\n-\n\n\nConfig endpoint for actual ingress loadbalancers\n\n\n\n\n\n\n\n\nGet Loadbalancer configuration\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nGET\n\n\nJSON\n\n\n200\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\n[{\n  \"force_https\": false,\n  \"name\": \"hello-world-lb\",\n  \"hostname\": \"hello.slush.org\",\n  \"ports\": {\n    \"https\": true,\n    \"http\": true\n  },\n  \"service_id\": \"1e896f56-f14b-471b-b9e4-a7066fe8ac5d\",\n  \"loadbalancer_id\": \"21d4f559-d021-4d6b-bec6-4c6251d804b2\",\n  \"network\": \"172.16.0.0/12 80.69.169.128/26\",\n  \"backends\": [],\n  \"enabled\": true,\n  \"source_port\": 80\n}, {\n  \"force_https\": true,\n  \"name\": \"slush-pass\",\n  \"hostname\": \"pass.slush.org\",\n  \"ports\": {\n    \"https\": true,\n    \"http\": true\n  },\n  \"service_id\": \"3fbb0a9a-885f-4975-9ace-2ca0f2d7d24f\",\n  \"loadbalancer_id\": \"270e7ac8-aa8a-4f15-b80f-f6b0e3132668\",\n  \"backends\": [{\n    \"instance_id\": \"f76f4365-2347-4a4b-8293-e31c68ed9551\",\n    \"address\": \"10.4.1.209\",\n    \"port\": 32771\n  }, {\n    \"instance_id\": \"f2a765f3-a722-4d69-a06f-cc5b0840a54e\",\n    \"address\": \"10.4.1.201\",\n    \"port\": 32771\n  }],\n  \"enabled\": true,\n  \"source_port\": 8080\n}]",
            "title": "Loadbalancers"
        },
        {
            "location": "/API/loadbalancers/#loadbalancers",
            "text": "Collection  Base URL  Format  Stability  Additional information      Loadbalancers  /api/v1/loadbalancers  JSON  -  -",
            "title": "Loadbalancers"
        },
        {
            "location": "/API/loadbalancers/#list-all-loadbalancers",
            "text": "Method  Format  Response Status (OK)  Stability  Additional information      GET  JSON  200  -  -     {\n  \"loadbalancers\": [\n    {\n      \"ports\": {\n        \"https\": true,\n        \"http\": true\n      },\n      \"force_https\": false,\n      \"source_port\": 80,\n      \"network\": \"172.16.0.0/12 80.69.169.128/26\",\n      \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n      \"hostname\": \"hello.slush.org\",\n      \"enabled\": true,\n      \"name\": \"hello-world\",\n      \"loadbalancer_id\": \"0308e104-adc2-4868-b154-d42cf75a720c\"\n    },\n    {\n      \"ports\": {\n        \"https\": false,\n        \"http\": true\n      },\n      \"force_https\": false,\n      \"source_port\": 80,\n      \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n      \"hostname\": \"hello2.slush.org\",\n      \"enabled\": true,\n      \"name\": \"hello-world2\",\n      \"loadbalancer_id\": \"a4ec5443-9a12-4fec-96b1-92bb2c2c6eb5\"\n    },\n    {\n      \"ports\": {\n        \"https\": false,\n        \"http\": true\n      },\n      \"force_https\": false,\n      \"source_port\": 8080,\n      \"service_id\": \"5a1496e6-13e8-444e-a2ad-3f740a1be837\",\n      \"hostname\": \"hello3.slush.org\",\n      \"enabled\": true,\n      \"name\": \"hello-world3\",\n      \"loadbalancer_id\": \"1c53a7e4-d9ce-4b19-ac39-167dd80aca50\"\n    }\n  ]\n}",
            "title": "List All Loadbalancers"
        },
        {
            "location": "/API/loadbalancers/#create-a-new-loadbalancer",
            "text": "Creating new loadbalancer takes name, hostname, service_id for service to be loadbalancer and source port of the service\nThere is also optional  network  argument, you can use it to limit the source address of incoming requests.\nUsed for example with internal services.     Method  Format  Response Status (OK)  Stability  Additional information      POST  JSON  201  -  -",
            "title": "Create a New Loadbalancer"
        },
        {
            "location": "/API/loadbalancers/#request",
            "text": "{\n    \"name\": \"hello-world2\",\n    \"enabled\": true,\n    \"hostname\": \"hello2.slush.org\",\n    \"network\": \"172.16.0.0/12\",\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"source_port\": 80,\n    \"force_https\": false,\n    \"ports\": {\"http\": true, \"https\": false}\n}",
            "title": "Request"
        },
        {
            "location": "/API/loadbalancers/#response",
            "text": "{\n  \"loadbalancer\": {\n    \"loadbalancer_id\": \"229b7a00-85d1-4f23-9238-277bc9d25337\",\n    \"name\": \"hello-world2\",\n    \"enabled\": true,\n    \"hostname\": \"hello2.slush.org\",\n    \"network\": \"172.16.0.0/12\",\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"source_port\": 80,\n    \"force_https\": false,\n    \"ports\": {\n      \"http\": true,\n      \"https\": false\n    }\n  }\n}",
            "title": "Response"
        },
        {
            "location": "/API/loadbalancers/#single-loadbalancer",
            "text": "Collection  Base URL  Format  Stability  Additional information      Single loadbalancer  /api/v1/loadbalancers/{loadbalancer_id}  JSON  -  -",
            "title": "Single loadbalancer"
        },
        {
            "location": "/API/loadbalancers/#read-loadbalancer",
            "text": "Method  Format  Response Status (OK)  Stability  Additional information      GET  JSON  200  -  -     {\n  \"loadbalancer\": {\n    \"ports\": {\n      \"https\": false,\n      \"http\": true\n    },\n    \"force_https\": false,\n    \"source_port\": 80,\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"hostname\": \"hello2.slush.org\",\n    \"network\": \"172.16.0.0/12 80.69.169.128/26\",\n    \"enabled\": true,\n    \"name\": \"hello-world2\",\n    \"loadbalancer_id\": \"229b7a00-85d1-4f23-9238-277bc9d25337\"\n  }\n}",
            "title": "Read Loadbalancer"
        },
        {
            "location": "/API/loadbalancers/#update-loadbalancer",
            "text": "This is partial operation and you can just PUT different fields.\nChanges are merged in server and returned the full document     Method  Format  Response Status (OK)  Stability  Additional information      PUT  JSON  200  -  -",
            "title": "Update Loadbalancer"
        },
        {
            "location": "/API/loadbalancers/#request_1",
            "text": "{\n    \"force_https\": true\n}",
            "title": "Request"
        },
        {
            "location": "/API/loadbalancers/#response_1",
            "text": "{\n  \"loadbalancer\": {\n    \"ports\": {\n      \"https\": false,\n      \"http\": true\n    },\n    \"force_https\": true,\n    \"source_port\": 80,\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"hostname\": \"hello2.slush.org\",\n    \"enabled\": true,\n    \"name\": \"hello-world2\",\n    \"loadbalancer_id\": \"229b7a00-85d1-4f23-9238-277bc9d25337\"\n  }\n}",
            "title": "Response"
        },
        {
            "location": "/API/loadbalancers/#loadbalancer-configuration",
            "text": "Collection  Base URL  Format  Stability  Additional information      Loadbalancer config  /api/v1/loadbalancers/config  JSON  -  Config endpoint for actual ingress loadbalancers",
            "title": "Loadbalancer configuration"
        },
        {
            "location": "/API/loadbalancers/#get-loadbalancer-configuration",
            "text": "Method  Format  Response Status (OK)  Stability  Additional information      GET  JSON  200  -  -     [{\n  \"force_https\": false,\n  \"name\": \"hello-world-lb\",\n  \"hostname\": \"hello.slush.org\",\n  \"ports\": {\n    \"https\": true,\n    \"http\": true\n  },\n  \"service_id\": \"1e896f56-f14b-471b-b9e4-a7066fe8ac5d\",\n  \"loadbalancer_id\": \"21d4f559-d021-4d6b-bec6-4c6251d804b2\",\n  \"network\": \"172.16.0.0/12 80.69.169.128/26\",\n  \"backends\": [],\n  \"enabled\": true,\n  \"source_port\": 80\n}, {\n  \"force_https\": true,\n  \"name\": \"slush-pass\",\n  \"hostname\": \"pass.slush.org\",\n  \"ports\": {\n    \"https\": true,\n    \"http\": true\n  },\n  \"service_id\": \"3fbb0a9a-885f-4975-9ace-2ca0f2d7d24f\",\n  \"loadbalancer_id\": \"270e7ac8-aa8a-4f15-b80f-f6b0e3132668\",\n  \"backends\": [{\n    \"instance_id\": \"f76f4365-2347-4a4b-8293-e31c68ed9551\",\n    \"address\": \"10.4.1.209\",\n    \"port\": 32771\n  }, {\n    \"instance_id\": \"f2a765f3-a722-4d69-a06f-cc5b0840a54e\",\n    \"address\": \"10.4.1.201\",\n    \"port\": 32771\n  }],\n  \"enabled\": true,\n  \"source_port\": 8080\n}]",
            "title": "Get Loadbalancer configuration"
        },
        {
            "location": "/API/services/",
            "text": "Services\n\n\n\n\n\n\n\n\nCollection\n\n\nBase URL\n\n\nFormat\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nServices\n\n\n/api/v1/services\n\n\nJSON\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nList All Services\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nGET\n\n\nJSON\n\n\n200\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nResponse\n\n\n{\n  \"services\": [\n    {\n      \"name\": \"hello-world3\",\n      \"memory\": 700,\n      \"ports\": [\n                  {\n                    \"port\": 80,\n                    \"protocol\": \"tcp\"\n                  }\n      ],\n      \"instances\": 1,\n      \"image\": \"tutum/hello-world\",\n      \"requirements\": [\"SSD\"],\n      \"environment\": [\n        {\n          \"value\": \"80\",\n          \"key\": \"PORT\"\n        }\n      ],\n      \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n      \"version\": \"hello4\",\n      \"enabled\": true,\n      \"cpu\": 1\n    },\n    {\n      \"name\": \"hello-world8000\",\n      \"memory\": 700,\n      \"ports\": [\n          {\n            \"port\": 80,\n            \"protocol\": \"tcp\"\n          },\n          {\n            \"port\": 8080,\n            \"protocol\": \"tcp\"\n          }\n      ],\n      \"instances\": 2,\n      \"image\": \"tutum/hello-world\",\n      \"environment\": [\n        {\n          \"value\": \"80\",\n          \"key\": \"PORT\"\n        }\n      ],\n      \"service_id\": \"5a1496e6-13e8-444e-a2ad-3f740a1be837\",\n      \"version\": \"hello1\",\n      \"enabled\": true,\n      \"cpu\": 1\n    },\n    {\n      \"name\": \"hello-world8000\",\n      \"memory\": 700,\n      \"ports\": [\n          {\n            \"port\": 80,\n            \"protocol\": \"tcp\"\n          },\n          {\n            \"port\": 8080,\n            \"protocol\": \"tcp\"\n          }\n      ],\n      \"instances\": 2,\n      \"image\": \"tutum/hello-world\",\n      \"environment\": [\n        {\n          \"value\": \"80\",\n          \"key\": \"PORT\"\n        }\n      ],\n      \"service_id\": \"491b2a26-000f-4630-ab2f-fe0222d03a0a\",\n      \"version\": \"hello1\",\n      \"enabled\": true,\n      \"cpu\": 1\n    }\n  ]\n}\n\n\n\n\n\nCreate a New Service\n\n\nCreating new service takes service name, image, ports, env, instance count and resource requirements.\n\n\nCPU requirement is part of CPU:s ie. one host has 2 cores so then you can put 4 CPU=0.5 services in one host.\nMemory requirements is MB of memory.\n\n\ninstances\n mark number of running containers in cluster. You can set this higher than the count of hosts in cluster but there will be only one instance of this service per host.\n\n\nversion\n must be different string than previous version. Affects only for already deployed services.\n\n\nimage\n full path to docker image repository\n\n\nrequirements\n optional requirements for host machine\n\n\nports\n you can specify just one integer between 0-65535 or define it with object notation.\nObject notation also accepts protocol definition (defaults to tcp).\n\n\ncommand\n optional command for docker image\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nPOST\n\n\nJSON\n\n\n201\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nRequest\n\n\n{\n    \"name\": \"hello-world8000\",\n    \"cpu\": 0.1,\n    \"enabled\": true,\n    \"memory\": 700,\n    \"command\": \"bash\",\n    \"instances\": 2,\n    \"requirements\": [\"SSD\", \"INTRANET\"],\n    \"version\": \"hello1\",\n    \"image\": \"tutum/hello-world\",\n    \"ports\": [\n        80,\n        {\n            \"port\": 8080,\n            \"protocol\": \"udp\"\n        }\n    ],\n    \"environment\": [{\"key\": \"PORT\", \"value\": \"80\"}]\n}\n\n\n\n\nResponse\n\n\n{\n    \"service\": {\n        \"name\": \"hello-world8000\",\n        \"memory\": 700,\n        \"ports\": [\n          {\n            \"port\": 80,\n            \"protocol\": \"tcp\"\n          },\n          {\n            \"port\": 8080,\n            \"protocol\": \"udp\"\n          }\n        ],\n        \"instances\": 2,\n        \"requirements\": [\"SSD\", \"INTRANET\"],\n        \"image\": \"tutum/hello-world\",\n        \"command\": \"bash\",\n        \"environment\": [\n            {\n                \"key\": \"PORT\",\n                \"value\": \"80\"\n            }\n        ],\n        \"service_id\": \"491b2a26-000f-4630-ab2f-fe0222d03a0a\",\n        \"version\": \"hello1\",\n        \"enabled\": true,\n        \"cpu\": 1\n    }\n}\n\n\n\n\nSingle service\n\n\n\n\n\n\n\n\nCollection\n\n\nBase URL\n\n\nFormat\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nSingle Service\n\n\n/api/v1/services/{service_id}\n\n\nJSON\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nrunning_on\n is readonly field\n\n\nRead Service\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nGET\n\n\nJSON\n\n\n200\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nResponse\n\n\n{\n  \"service\": {\n    \"name\": \"registration\",\n    \"memory\": 250,\n    \"running_on\": [{\n      \"instance_id\": \"0532c5f6-6eda-4319-b739-5a94e5384b44\",\n      \"address\": null,\n      \"port\": null,\n      \"source\": 8000\n    }, {\n      \"instance_id\": \"0532c5f6-6eda-4319-b739-5a94e5384b44\",\n      \"address\": \"10.4.1.201\",\n      \"port\": 32776,\n      \"source\": 80\n    }],\n    \"ports\": [80],\n    \"instances\": 1,\n    \"requirements\": [\"SSD\", \"INTRANET\"],\n    \"image\": \"repo1.slush.org:443\\/registration\",\n    \"environment\": [{\n      \"key\": \"MONGO_URI\",\n      \"value\": \"mongodb:\\/\\/10.1.0.226\\/slushreg\"\n    }, {\n      \"key\": \"AWS_HOST\",\n      \"value\": \"storage.slush.xyz\"\n    }, {\n      \"key\": \"SLUSHPASS_ACCESS_TOKEN_PATH\",\n      \"value\": \"\\/oauth\\/v2\\/token\"\n    }, {\n      \"key\": \"SLUSHPASS_AUTHORIZE_PATH\",\n      \"value\": \"\\/oauth\\/v2\\/authenticate\"\n    }, {\n      \"key\": \"SLUSHPASS_BASE_URL\",\n      \"value\": \"https:\\/\\/pass.slush.org\"\n    }, {\n      \"key\": \"REG_BASE_URL\",\n      \"value\": \"https:\\/\\/register.slush.org\"\n    }, {\n      \"key\": \"SHOP_BASE_URL\",\n      \"value\": \"https:\\/\\/shop.slush.org\"\n    }, {\n      \"key\": \"SERVER_PORT\",\n      \"value\": \"8000\"\n    }],\n    \"service_id\": \"294f7ba7-72d4-4318-b690-bf273a7c2d1c\",\n    \"version\": \"1\",\n    \"enabled\": true,\n    \"cpu\": 0.1\n  }\n}\n\n\n\n\nUpdate Service\n\n\nThis is partial operation and you can just PUT different fields.\nChanges are merged in server and returned the full document\nChanges are propagated to cluster asynchronously\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nPUT\n\n\nJSON\n\n\n202\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nRequest\n\n\n{\n    \"enabled\": false,\n    \"version\": \"hello2\"\n}\n\n\n\n\nResponse\n\n\n{\n  \"service\": {\n    \"_id\": \"570c101387d10657d803a2f9\",\n    \"name\": \"hello-world3\",\n    \"memory\": 700,\n    \"ports\": [\n      {\n        \"port\": 80,\n        \"protocol\": \"tcp\"\n      }\n    ],\n    \"instances\": 1,\n    \"requirements\": [\"SSD\"],\n    \"image\": \"tutum/hello-world\",\n    \"environment\": [\n      {\n        \"key\": \"PORT\",\n        \"value\": \"80\"\n      }\n    ],\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"version\": \"hello2\",\n    \"enabled\": false,\n    \"cpu\": 1\n  }\n}\n\n\n\n\nDelete Service\n\n\nThis removes service from halti. Note that you can also just disable service by setting enabled to false.\nProcess is asynchronous\n\n\n\n\n\n\n\n\nMethod\n\n\nFormat\n\n\nResponse Status (OK)\n\n\nStability\n\n\nAdditional information\n\n\n\n\n\n\n\n\n\n\nDELETE\n\n\nJSON\n\n\n202\n\n\n-\n\n\n-\n\n\n\n\n\n\n\n\nResponse (202)\n\n\n{\n  \"ack\": true\n}\n\n\n\n\nResponse (400)\n\n\n{\n  \"ack\": false,\n  \"error\": \"Service not found or remove not acknowledged\"\n}",
            "title": "Services"
        },
        {
            "location": "/API/services/#services",
            "text": "Collection  Base URL  Format  Stability  Additional information      Services  /api/v1/services  JSON  -  -",
            "title": "Services"
        },
        {
            "location": "/API/services/#list-all-services",
            "text": "Method  Format  Response Status (OK)  Stability  Additional information      GET  JSON  200  -  -",
            "title": "List All Services"
        },
        {
            "location": "/API/services/#response",
            "text": "{\n  \"services\": [\n    {\n      \"name\": \"hello-world3\",\n      \"memory\": 700,\n      \"ports\": [\n                  {\n                    \"port\": 80,\n                    \"protocol\": \"tcp\"\n                  }\n      ],\n      \"instances\": 1,\n      \"image\": \"tutum/hello-world\",\n      \"requirements\": [\"SSD\"],\n      \"environment\": [\n        {\n          \"value\": \"80\",\n          \"key\": \"PORT\"\n        }\n      ],\n      \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n      \"version\": \"hello4\",\n      \"enabled\": true,\n      \"cpu\": 1\n    },\n    {\n      \"name\": \"hello-world8000\",\n      \"memory\": 700,\n      \"ports\": [\n          {\n            \"port\": 80,\n            \"protocol\": \"tcp\"\n          },\n          {\n            \"port\": 8080,\n            \"protocol\": \"tcp\"\n          }\n      ],\n      \"instances\": 2,\n      \"image\": \"tutum/hello-world\",\n      \"environment\": [\n        {\n          \"value\": \"80\",\n          \"key\": \"PORT\"\n        }\n      ],\n      \"service_id\": \"5a1496e6-13e8-444e-a2ad-3f740a1be837\",\n      \"version\": \"hello1\",\n      \"enabled\": true,\n      \"cpu\": 1\n    },\n    {\n      \"name\": \"hello-world8000\",\n      \"memory\": 700,\n      \"ports\": [\n          {\n            \"port\": 80,\n            \"protocol\": \"tcp\"\n          },\n          {\n            \"port\": 8080,\n            \"protocol\": \"tcp\"\n          }\n      ],\n      \"instances\": 2,\n      \"image\": \"tutum/hello-world\",\n      \"environment\": [\n        {\n          \"value\": \"80\",\n          \"key\": \"PORT\"\n        }\n      ],\n      \"service_id\": \"491b2a26-000f-4630-ab2f-fe0222d03a0a\",\n      \"version\": \"hello1\",\n      \"enabled\": true,\n      \"cpu\": 1\n    }\n  ]\n}",
            "title": "Response"
        },
        {
            "location": "/API/services/#create-a-new-service",
            "text": "Creating new service takes service name, image, ports, env, instance count and resource requirements.  CPU requirement is part of CPU:s ie. one host has 2 cores so then you can put 4 CPU=0.5 services in one host.\nMemory requirements is MB of memory.  instances  mark number of running containers in cluster. You can set this higher than the count of hosts in cluster but there will be only one instance of this service per host.  version  must be different string than previous version. Affects only for already deployed services.  image  full path to docker image repository  requirements  optional requirements for host machine  ports  you can specify just one integer between 0-65535 or define it with object notation.\nObject notation also accepts protocol definition (defaults to tcp).  command  optional command for docker image     Method  Format  Response Status (OK)  Stability  Additional information      POST  JSON  201  -  -",
            "title": "Create a New Service"
        },
        {
            "location": "/API/services/#request",
            "text": "{\n    \"name\": \"hello-world8000\",\n    \"cpu\": 0.1,\n    \"enabled\": true,\n    \"memory\": 700,\n    \"command\": \"bash\",\n    \"instances\": 2,\n    \"requirements\": [\"SSD\", \"INTRANET\"],\n    \"version\": \"hello1\",\n    \"image\": \"tutum/hello-world\",\n    \"ports\": [\n        80,\n        {\n            \"port\": 8080,\n            \"protocol\": \"udp\"\n        }\n    ],\n    \"environment\": [{\"key\": \"PORT\", \"value\": \"80\"}]\n}",
            "title": "Request"
        },
        {
            "location": "/API/services/#response_1",
            "text": "{\n    \"service\": {\n        \"name\": \"hello-world8000\",\n        \"memory\": 700,\n        \"ports\": [\n          {\n            \"port\": 80,\n            \"protocol\": \"tcp\"\n          },\n          {\n            \"port\": 8080,\n            \"protocol\": \"udp\"\n          }\n        ],\n        \"instances\": 2,\n        \"requirements\": [\"SSD\", \"INTRANET\"],\n        \"image\": \"tutum/hello-world\",\n        \"command\": \"bash\",\n        \"environment\": [\n            {\n                \"key\": \"PORT\",\n                \"value\": \"80\"\n            }\n        ],\n        \"service_id\": \"491b2a26-000f-4630-ab2f-fe0222d03a0a\",\n        \"version\": \"hello1\",\n        \"enabled\": true,\n        \"cpu\": 1\n    }\n}",
            "title": "Response"
        },
        {
            "location": "/API/services/#single-service",
            "text": "Collection  Base URL  Format  Stability  Additional information      Single Service  /api/v1/services/{service_id}  JSON  -  -     running_on  is readonly field",
            "title": "Single service"
        },
        {
            "location": "/API/services/#read-service",
            "text": "Method  Format  Response Status (OK)  Stability  Additional information      GET  JSON  200  -  -",
            "title": "Read Service"
        },
        {
            "location": "/API/services/#response_2",
            "text": "{\n  \"service\": {\n    \"name\": \"registration\",\n    \"memory\": 250,\n    \"running_on\": [{\n      \"instance_id\": \"0532c5f6-6eda-4319-b739-5a94e5384b44\",\n      \"address\": null,\n      \"port\": null,\n      \"source\": 8000\n    }, {\n      \"instance_id\": \"0532c5f6-6eda-4319-b739-5a94e5384b44\",\n      \"address\": \"10.4.1.201\",\n      \"port\": 32776,\n      \"source\": 80\n    }],\n    \"ports\": [80],\n    \"instances\": 1,\n    \"requirements\": [\"SSD\", \"INTRANET\"],\n    \"image\": \"repo1.slush.org:443\\/registration\",\n    \"environment\": [{\n      \"key\": \"MONGO_URI\",\n      \"value\": \"mongodb:\\/\\/10.1.0.226\\/slushreg\"\n    }, {\n      \"key\": \"AWS_HOST\",\n      \"value\": \"storage.slush.xyz\"\n    }, {\n      \"key\": \"SLUSHPASS_ACCESS_TOKEN_PATH\",\n      \"value\": \"\\/oauth\\/v2\\/token\"\n    }, {\n      \"key\": \"SLUSHPASS_AUTHORIZE_PATH\",\n      \"value\": \"\\/oauth\\/v2\\/authenticate\"\n    }, {\n      \"key\": \"SLUSHPASS_BASE_URL\",\n      \"value\": \"https:\\/\\/pass.slush.org\"\n    }, {\n      \"key\": \"REG_BASE_URL\",\n      \"value\": \"https:\\/\\/register.slush.org\"\n    }, {\n      \"key\": \"SHOP_BASE_URL\",\n      \"value\": \"https:\\/\\/shop.slush.org\"\n    }, {\n      \"key\": \"SERVER_PORT\",\n      \"value\": \"8000\"\n    }],\n    \"service_id\": \"294f7ba7-72d4-4318-b690-bf273a7c2d1c\",\n    \"version\": \"1\",\n    \"enabled\": true,\n    \"cpu\": 0.1\n  }\n}",
            "title": "Response"
        },
        {
            "location": "/API/services/#update-service",
            "text": "This is partial operation and you can just PUT different fields.\nChanges are merged in server and returned the full document\nChanges are propagated to cluster asynchronously     Method  Format  Response Status (OK)  Stability  Additional information      PUT  JSON  202  -  -",
            "title": "Update Service"
        },
        {
            "location": "/API/services/#request_1",
            "text": "{\n    \"enabled\": false,\n    \"version\": \"hello2\"\n}",
            "title": "Request"
        },
        {
            "location": "/API/services/#response_3",
            "text": "{\n  \"service\": {\n    \"_id\": \"570c101387d10657d803a2f9\",\n    \"name\": \"hello-world3\",\n    \"memory\": 700,\n    \"ports\": [\n      {\n        \"port\": 80,\n        \"protocol\": \"tcp\"\n      }\n    ],\n    \"instances\": 1,\n    \"requirements\": [\"SSD\"],\n    \"image\": \"tutum/hello-world\",\n    \"environment\": [\n      {\n        \"key\": \"PORT\",\n        \"value\": \"80\"\n      }\n    ],\n    \"service_id\": \"ececb4a5-7d64-4b1a-b0cc-45e26e4c9603\",\n    \"version\": \"hello2\",\n    \"enabled\": false,\n    \"cpu\": 1\n  }\n}",
            "title": "Response"
        },
        {
            "location": "/API/services/#delete-service",
            "text": "This removes service from halti. Note that you can also just disable service by setting enabled to false.\nProcess is asynchronous     Method  Format  Response Status (OK)  Stability  Additional information      DELETE  JSON  202  -  -",
            "title": "Delete Service"
        },
        {
            "location": "/API/services/#response-202",
            "text": "{\n  \"ack\": true\n}",
            "title": "Response (202)"
        },
        {
            "location": "/API/services/#response-400",
            "text": "{\n  \"ack\": false,\n  \"error\": \"Service not found or remove not acknowledged\"\n}",
            "title": "Response (400)"
        }
    ]
}